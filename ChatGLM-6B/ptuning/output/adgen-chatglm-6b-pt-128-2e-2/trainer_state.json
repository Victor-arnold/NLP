{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.946907498631637,
  "global_step": 10000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 0.01998,
      "loss": 2.8259,
      "step": 10
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.019960000000000002,
      "loss": 1.8182,
      "step": 20
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.01994,
      "loss": 1.9251,
      "step": 30
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.01992,
      "loss": 1.8543,
      "step": 40
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0199,
      "loss": 1.8941,
      "step": 50
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.019880000000000002,
      "loss": 1.707,
      "step": 60
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.01986,
      "loss": 1.6388,
      "step": 70
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.01984,
      "loss": 1.8025,
      "step": 80
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.01982,
      "loss": 1.7313,
      "step": 90
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0198,
      "loss": 1.8736,
      "step": 100
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.01978,
      "loss": 1.6666,
      "step": 110
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.01976,
      "loss": 1.517,
      "step": 120
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.01974,
      "loss": 1.5925,
      "step": 130
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.01972,
      "loss": 1.5561,
      "step": 140
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0197,
      "loss": 1.7342,
      "step": 150
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.01968,
      "loss": 1.718,
      "step": 160
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.01966,
      "loss": 1.7253,
      "step": 170
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.01964,
      "loss": 1.7117,
      "step": 180
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.01962,
      "loss": 1.764,
      "step": 190
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0196,
      "loss": 1.5952,
      "step": 200
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.01958,
      "loss": 1.653,
      "step": 210
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.01956,
      "loss": 1.6397,
      "step": 220
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.01954,
      "loss": 1.5453,
      "step": 230
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.01952,
      "loss": 1.588,
      "step": 240
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0195,
      "loss": 1.6625,
      "step": 250
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.01948,
      "loss": 1.7474,
      "step": 260
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.01946,
      "loss": 1.6234,
      "step": 270
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.01944,
      "loss": 1.5603,
      "step": 280
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.01942,
      "loss": 1.5832,
      "step": 290
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0194,
      "loss": 1.5149,
      "step": 300
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.01938,
      "loss": 1.6616,
      "step": 310
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.01936,
      "loss": 1.6337,
      "step": 320
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.01934,
      "loss": 1.7801,
      "step": 330
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.01932,
      "loss": 1.6442,
      "step": 340
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0193,
      "loss": 1.5953,
      "step": 350
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.01928,
      "loss": 1.494,
      "step": 360
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.01926,
      "loss": 1.6323,
      "step": 370
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.01924,
      "loss": 1.7339,
      "step": 380
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.01922,
      "loss": 1.6925,
      "step": 390
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0192,
      "loss": 1.6939,
      "step": 400
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.01918,
      "loss": 1.583,
      "step": 410
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.01916,
      "loss": 1.4917,
      "step": 420
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.01914,
      "loss": 1.6178,
      "step": 430
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.019119999999999998,
      "loss": 1.5834,
      "step": 440
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0191,
      "loss": 1.6633,
      "step": 450
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.01908,
      "loss": 1.6939,
      "step": 460
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.01906,
      "loss": 1.6527,
      "step": 470
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.019039999999999998,
      "loss": 1.4494,
      "step": 480
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.01902,
      "loss": 1.6297,
      "step": 490
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.019,
      "loss": 1.576,
      "step": 500
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.01898,
      "loss": 1.6669,
      "step": 510
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.01896,
      "loss": 1.6171,
      "step": 520
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.01894,
      "loss": 1.4755,
      "step": 530
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.01892,
      "loss": 1.5777,
      "step": 540
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0189,
      "loss": 1.7991,
      "step": 550
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.01888,
      "loss": 1.6723,
      "step": 560
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.01886,
      "loss": 1.6843,
      "step": 570
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.01884,
      "loss": 1.5887,
      "step": 580
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.01882,
      "loss": 1.5722,
      "step": 590
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0188,
      "loss": 1.7263,
      "step": 600
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.018779999999999998,
      "loss": 1.6136,
      "step": 610
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.01876,
      "loss": 1.5726,
      "step": 620
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.018740000000000003,
      "loss": 1.5274,
      "step": 630
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.01872,
      "loss": 1.5392,
      "step": 640
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0187,
      "loss": 1.7691,
      "step": 650
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.018680000000000002,
      "loss": 1.5655,
      "step": 660
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.018660000000000003,
      "loss": 1.5935,
      "step": 670
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.01864,
      "loss": 1.6499,
      "step": 680
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.01862,
      "loss": 1.6874,
      "step": 690
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.018600000000000002,
      "loss": 1.614,
      "step": 700
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.018580000000000003,
      "loss": 1.6656,
      "step": 710
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.01856,
      "loss": 1.6156,
      "step": 720
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.01854,
      "loss": 1.632,
      "step": 730
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.018520000000000002,
      "loss": 1.6045,
      "step": 740
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.018500000000000003,
      "loss": 1.6915,
      "step": 750
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.01848,
      "loss": 1.5457,
      "step": 760
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.01846,
      "loss": 1.5839,
      "step": 770
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.01844,
      "loss": 1.6666,
      "step": 780
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.018420000000000002,
      "loss": 1.436,
      "step": 790
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0184,
      "loss": 1.6752,
      "step": 800
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.01838,
      "loss": 1.5628,
      "step": 810
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.01836,
      "loss": 1.5767,
      "step": 820
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.018340000000000002,
      "loss": 1.5588,
      "step": 830
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.01832,
      "loss": 1.6034,
      "step": 840
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0183,
      "loss": 1.639,
      "step": 850
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.01828,
      "loss": 1.4953,
      "step": 860
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.018260000000000002,
      "loss": 1.4673,
      "step": 870
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.018240000000000003,
      "loss": 1.609,
      "step": 880
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.01822,
      "loss": 1.6222,
      "step": 890
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0182,
      "loss": 1.5583,
      "step": 900
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.01818,
      "loss": 1.6226,
      "step": 910
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.018160000000000003,
      "loss": 1.3999,
      "step": 920
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.01814,
      "loss": 1.3487,
      "step": 930
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.01812,
      "loss": 1.367,
      "step": 940
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0181,
      "loss": 1.3293,
      "step": 950
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.018080000000000002,
      "loss": 1.2366,
      "step": 960
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.01806,
      "loss": 1.3638,
      "step": 970
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.01804,
      "loss": 1.3217,
      "step": 980
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.01802,
      "loss": 1.4319,
      "step": 990
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.018000000000000002,
      "loss": 1.3613,
      "step": 1000
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.01798,
      "loss": 1.4173,
      "step": 1010
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.01796,
      "loss": 1.2961,
      "step": 1020
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.01794,
      "loss": 1.359,
      "step": 1030
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.017920000000000002,
      "loss": 1.2918,
      "step": 1040
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0179,
      "loss": 1.4009,
      "step": 1050
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.01788,
      "loss": 1.2975,
      "step": 1060
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.01786,
      "loss": 1.3233,
      "step": 1070
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.01784,
      "loss": 1.4356,
      "step": 1080
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.01782,
      "loss": 1.5023,
      "step": 1090
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0178,
      "loss": 1.3882,
      "step": 1100
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.01778,
      "loss": 1.3701,
      "step": 1110
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.01776,
      "loss": 1.3221,
      "step": 1120
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.017740000000000002,
      "loss": 1.2479,
      "step": 1130
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.01772,
      "loss": 1.3551,
      "step": 1140
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0177,
      "loss": 1.3441,
      "step": 1150
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.01768,
      "loss": 1.2565,
      "step": 1160
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.017660000000000002,
      "loss": 1.3921,
      "step": 1170
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.01764,
      "loss": 1.3382,
      "step": 1180
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.01762,
      "loss": 1.2711,
      "step": 1190
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0176,
      "loss": 1.4918,
      "step": 1200
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.017580000000000002,
      "loss": 1.4019,
      "step": 1210
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.01756,
      "loss": 1.4139,
      "step": 1220
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.01754,
      "loss": 1.5148,
      "step": 1230
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.01752,
      "loss": 1.3964,
      "step": 1240
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0175,
      "loss": 1.4053,
      "step": 1250
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.01748,
      "loss": 1.3565,
      "step": 1260
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.01746,
      "loss": 1.4458,
      "step": 1270
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.01744,
      "loss": 1.2351,
      "step": 1280
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.01742,
      "loss": 1.4534,
      "step": 1290
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0174,
      "loss": 1.4994,
      "step": 1300
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.01738,
      "loss": 1.3627,
      "step": 1310
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.01736,
      "loss": 1.3592,
      "step": 1320
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.01734,
      "loss": 1.4319,
      "step": 1330
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.01732,
      "loss": 1.5065,
      "step": 1340
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0173,
      "loss": 1.4404,
      "step": 1350
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.01728,
      "loss": 1.4543,
      "step": 1360
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.01726,
      "loss": 1.2166,
      "step": 1370
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.017240000000000002,
      "loss": 1.2451,
      "step": 1380
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.01722,
      "loss": 1.3235,
      "step": 1390
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0172,
      "loss": 1.3076,
      "step": 1400
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.01718,
      "loss": 1.3503,
      "step": 1410
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.01716,
      "loss": 1.4783,
      "step": 1420
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.01714,
      "loss": 1.3567,
      "step": 1430
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.01712,
      "loss": 1.3841,
      "step": 1440
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0171,
      "loss": 1.3509,
      "step": 1450
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.01708,
      "loss": 1.5088,
      "step": 1460
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.01706,
      "loss": 1.3877,
      "step": 1470
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.01704,
      "loss": 1.3616,
      "step": 1480
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.01702,
      "loss": 1.4571,
      "step": 1490
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.017,
      "loss": 1.4835,
      "step": 1500
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.01698,
      "loss": 1.4848,
      "step": 1510
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.01696,
      "loss": 1.5524,
      "step": 1520
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.01694,
      "loss": 1.3727,
      "step": 1530
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.01692,
      "loss": 1.3351,
      "step": 1540
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0169,
      "loss": 1.3892,
      "step": 1550
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.01688,
      "loss": 1.2176,
      "step": 1560
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.01686,
      "loss": 1.4729,
      "step": 1570
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.01684,
      "loss": 1.2256,
      "step": 1580
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.016819999999999998,
      "loss": 1.3524,
      "step": 1590
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0168,
      "loss": 1.2833,
      "step": 1600
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.01678,
      "loss": 1.2038,
      "step": 1610
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.01676,
      "loss": 1.2712,
      "step": 1620
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.01674,
      "loss": 1.3318,
      "step": 1630
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.01672,
      "loss": 1.4514,
      "step": 1640
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0167,
      "loss": 1.5039,
      "step": 1650
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.01668,
      "loss": 1.3943,
      "step": 1660
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.01666,
      "loss": 1.3561,
      "step": 1670
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.01664,
      "loss": 1.4046,
      "step": 1680
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.01662,
      "loss": 1.449,
      "step": 1690
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0166,
      "loss": 1.3038,
      "step": 1700
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.01658,
      "loss": 1.4004,
      "step": 1710
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.01656,
      "loss": 1.3484,
      "step": 1720
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.01654,
      "loss": 1.4331,
      "step": 1730
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.01652,
      "loss": 1.4835,
      "step": 1740
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0165,
      "loss": 1.2271,
      "step": 1750
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.016479999999999998,
      "loss": 1.366,
      "step": 1760
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.01646,
      "loss": 1.2289,
      "step": 1770
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.01644,
      "loss": 1.2795,
      "step": 1780
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.01642,
      "loss": 1.3407,
      "step": 1790
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.016399999999999998,
      "loss": 1.592,
      "step": 1800
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.01638,
      "loss": 1.3199,
      "step": 1810
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.01636,
      "loss": 1.2891,
      "step": 1820
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.01634,
      "loss": 1.3237,
      "step": 1830
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.016319999999999998,
      "loss": 1.0341,
      "step": 1840
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0163,
      "loss": 1.1873,
      "step": 1850
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.01628,
      "loss": 1.1257,
      "step": 1860
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.01626,
      "loss": 1.0474,
      "step": 1870
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.01624,
      "loss": 0.986,
      "step": 1880
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.016220000000000002,
      "loss": 1.1065,
      "step": 1890
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.016200000000000003,
      "loss": 1.077,
      "step": 1900
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.01618,
      "loss": 1.1641,
      "step": 1910
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.01616,
      "loss": 1.1015,
      "step": 1920
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.01614,
      "loss": 1.071,
      "step": 1930
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.016120000000000002,
      "loss": 1.0777,
      "step": 1940
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0161,
      "loss": 1.0398,
      "step": 1950
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.01608,
      "loss": 1.0459,
      "step": 1960
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.01606,
      "loss": 1.0626,
      "step": 1970
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.016040000000000002,
      "loss": 1.0111,
      "step": 1980
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.01602,
      "loss": 1.008,
      "step": 1990
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.016,
      "loss": 1.1026,
      "step": 2000
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.01598,
      "loss": 1.1118,
      "step": 2010
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.015960000000000002,
      "loss": 1.1307,
      "step": 2020
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.015940000000000003,
      "loss": 1.1355,
      "step": 2030
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.01592,
      "loss": 1.1466,
      "step": 2040
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0159,
      "loss": 1.1795,
      "step": 2050
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.015880000000000002,
      "loss": 1.151,
      "step": 2060
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.015860000000000003,
      "loss": 1.0653,
      "step": 2070
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.01584,
      "loss": 1.2427,
      "step": 2080
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.01582,
      "loss": 1.1326,
      "step": 2090
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0158,
      "loss": 1.1944,
      "step": 2100
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.015780000000000002,
      "loss": 1.044,
      "step": 2110
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.01576,
      "loss": 1.0119,
      "step": 2120
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.01574,
      "loss": 1.2041,
      "step": 2130
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.01572,
      "loss": 1.2168,
      "step": 2140
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.015700000000000002,
      "loss": 1.0589,
      "step": 2150
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.01568,
      "loss": 1.0934,
      "step": 2160
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.01566,
      "loss": 1.0851,
      "step": 2170
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.01564,
      "loss": 1.1419,
      "step": 2180
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.01562,
      "loss": 1.091,
      "step": 2190
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.015600000000000001,
      "loss": 1.1642,
      "step": 2200
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.01558,
      "loss": 1.055,
      "step": 2210
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.015560000000000001,
      "loss": 1.2134,
      "step": 2220
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.01554,
      "loss": 1.1508,
      "step": 2230
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.01552,
      "loss": 1.0683,
      "step": 2240
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.015500000000000002,
      "loss": 1.009,
      "step": 2250
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.01548,
      "loss": 1.124,
      "step": 2260
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.015460000000000002,
      "loss": 1.163,
      "step": 2270
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.01544,
      "loss": 1.0686,
      "step": 2280
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.015420000000000001,
      "loss": 1.1171,
      "step": 2290
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0154,
      "loss": 1.11,
      "step": 2300
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.015380000000000001,
      "loss": 1.0855,
      "step": 2310
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.01536,
      "loss": 1.0595,
      "step": 2320
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.015340000000000001,
      "loss": 1.1384,
      "step": 2330
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.01532,
      "loss": 1.0903,
      "step": 2340
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.015300000000000001,
      "loss": 1.1022,
      "step": 2350
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.01528,
      "loss": 1.1421,
      "step": 2360
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.015260000000000001,
      "loss": 1.1128,
      "step": 2370
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.01524,
      "loss": 1.1443,
      "step": 2380
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.015220000000000001,
      "loss": 1.0749,
      "step": 2390
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0152,
      "loss": 1.0978,
      "step": 2400
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.01518,
      "loss": 1.0384,
      "step": 2410
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.01516,
      "loss": 1.1848,
      "step": 2420
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.01514,
      "loss": 1.1156,
      "step": 2430
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.01512,
      "loss": 1.0625,
      "step": 2440
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0151,
      "loss": 1.2085,
      "step": 2450
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.01508,
      "loss": 1.1077,
      "step": 2460
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.01506,
      "loss": 1.1701,
      "step": 2470
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.01504,
      "loss": 1.1306,
      "step": 2480
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.01502,
      "loss": 0.9898,
      "step": 2490
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.015,
      "loss": 1.1644,
      "step": 2500
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.01498,
      "loss": 1.063,
      "step": 2510
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.014960000000000001,
      "loss": 1.11,
      "step": 2520
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.01494,
      "loss": 1.1492,
      "step": 2530
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.014920000000000001,
      "loss": 1.0489,
      "step": 2540
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0149,
      "loss": 1.0341,
      "step": 2550
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.01488,
      "loss": 1.2346,
      "step": 2560
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.01486,
      "loss": 1.238,
      "step": 2570
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.01484,
      "loss": 1.1507,
      "step": 2580
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.01482,
      "loss": 1.1481,
      "step": 2590
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0148,
      "loss": 1.1349,
      "step": 2600
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.01478,
      "loss": 1.1479,
      "step": 2610
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.01476,
      "loss": 1.1007,
      "step": 2620
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.01474,
      "loss": 0.9808,
      "step": 2630
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.01472,
      "loss": 1.1439,
      "step": 2640
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0147,
      "loss": 1.0874,
      "step": 2650
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.01468,
      "loss": 1.1106,
      "step": 2660
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.01466,
      "loss": 1.0213,
      "step": 2670
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.01464,
      "loss": 1.1624,
      "step": 2680
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.01462,
      "loss": 1.0775,
      "step": 2690
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0146,
      "loss": 1.1818,
      "step": 2700
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.01458,
      "loss": 1.1385,
      "step": 2710
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.01456,
      "loss": 1.2092,
      "step": 2720
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.014539999999999999,
      "loss": 1.2511,
      "step": 2730
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.01452,
      "loss": 1.1397,
      "step": 2740
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.014499999999999999,
      "loss": 0.992,
      "step": 2750
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.01448,
      "loss": 0.8368,
      "step": 2760
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.01446,
      "loss": 0.9593,
      "step": 2770
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.01444,
      "loss": 0.8822,
      "step": 2780
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.01442,
      "loss": 0.8354,
      "step": 2790
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0144,
      "loss": 0.8604,
      "step": 2800
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.01438,
      "loss": 0.8119,
      "step": 2810
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.01436,
      "loss": 0.8856,
      "step": 2820
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.01434,
      "loss": 0.8411,
      "step": 2830
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.01432,
      "loss": 0.89,
      "step": 2840
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0143,
      "loss": 0.812,
      "step": 2850
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.01428,
      "loss": 0.8294,
      "step": 2860
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.01426,
      "loss": 0.8377,
      "step": 2870
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.01424,
      "loss": 0.7715,
      "step": 2880
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.01422,
      "loss": 0.8339,
      "step": 2890
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.014199999999999999,
      "loss": 0.8042,
      "step": 2900
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.01418,
      "loss": 0.9362,
      "step": 2910
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.014159999999999999,
      "loss": 0.7515,
      "step": 2920
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.01414,
      "loss": 0.9698,
      "step": 2930
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.014119999999999999,
      "loss": 0.9677,
      "step": 2940
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.0141,
      "loss": 0.8418,
      "step": 2950
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.014079999999999999,
      "loss": 0.8286,
      "step": 2960
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.01406,
      "loss": 0.9106,
      "step": 2970
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.014039999999999999,
      "loss": 0.967,
      "step": 2980
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.01402,
      "loss": 0.8755,
      "step": 2990
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.013999999999999999,
      "loss": 0.8321,
      "step": 3000
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.01398,
      "loss": 0.812,
      "step": 3010
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.01396,
      "loss": 0.8971,
      "step": 3020
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.01394,
      "loss": 0.9099,
      "step": 3030
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.01392,
      "loss": 0.9074,
      "step": 3040
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0139,
      "loss": 0.7377,
      "step": 3050
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.01388,
      "loss": 0.8242,
      "step": 3060
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.013859999999999999,
      "loss": 0.8618,
      "step": 3070
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.01384,
      "loss": 0.8466,
      "step": 3080
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.013819999999999999,
      "loss": 0.882,
      "step": 3090
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.0138,
      "loss": 0.8731,
      "step": 3100
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.013779999999999999,
      "loss": 0.8182,
      "step": 3110
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.01376,
      "loss": 0.9018,
      "step": 3120
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.013740000000000002,
      "loss": 0.9139,
      "step": 3130
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.013720000000000001,
      "loss": 0.9444,
      "step": 3140
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.013700000000000002,
      "loss": 0.8505,
      "step": 3150
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.013680000000000001,
      "loss": 0.7749,
      "step": 3160
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.013660000000000002,
      "loss": 0.9347,
      "step": 3170
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.013640000000000001,
      "loss": 0.8758,
      "step": 3180
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.013620000000000002,
      "loss": 0.9089,
      "step": 3190
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.013600000000000001,
      "loss": 0.9187,
      "step": 3200
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.013580000000000002,
      "loss": 0.8378,
      "step": 3210
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.013560000000000001,
      "loss": 0.9271,
      "step": 3220
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.013540000000000002,
      "loss": 0.7955,
      "step": 3230
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.01352,
      "loss": 0.8331,
      "step": 3240
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.013500000000000002,
      "loss": 0.9513,
      "step": 3250
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.01348,
      "loss": 0.8509,
      "step": 3260
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.013460000000000001,
      "loss": 0.8585,
      "step": 3270
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.01344,
      "loss": 0.844,
      "step": 3280
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.013420000000000001,
      "loss": 0.9218,
      "step": 3290
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.0134,
      "loss": 0.844,
      "step": 3300
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.013380000000000001,
      "loss": 0.8271,
      "step": 3310
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.01336,
      "loss": 0.9163,
      "step": 3320
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.013340000000000001,
      "loss": 0.8576,
      "step": 3330
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.01332,
      "loss": 0.8602,
      "step": 3340
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.013300000000000001,
      "loss": 0.8443,
      "step": 3350
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.01328,
      "loss": 0.8375,
      "step": 3360
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.013260000000000001,
      "loss": 0.9464,
      "step": 3370
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.013240000000000002,
      "loss": 0.873,
      "step": 3380
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.01322,
      "loss": 0.8462,
      "step": 3390
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.013200000000000002,
      "loss": 0.8968,
      "step": 3400
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.01318,
      "loss": 0.9318,
      "step": 3410
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.013160000000000002,
      "loss": 1.0126,
      "step": 3420
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.01314,
      "loss": 0.8427,
      "step": 3430
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.013120000000000001,
      "loss": 0.919,
      "step": 3440
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.0131,
      "loss": 0.8558,
      "step": 3450
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.013080000000000001,
      "loss": 0.9428,
      "step": 3460
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.01306,
      "loss": 0.9183,
      "step": 3470
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.013040000000000001,
      "loss": 0.9565,
      "step": 3480
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.01302,
      "loss": 0.8449,
      "step": 3490
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.013000000000000001,
      "loss": 0.8947,
      "step": 3500
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.01298,
      "loss": 0.9166,
      "step": 3510
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.012960000000000001,
      "loss": 0.8094,
      "step": 3520
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.01294,
      "loss": 0.7854,
      "step": 3530
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.012920000000000001,
      "loss": 0.8661,
      "step": 3540
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.0129,
      "loss": 0.8735,
      "step": 3550
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.01288,
      "loss": 0.8588,
      "step": 3560
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.01286,
      "loss": 1.0047,
      "step": 3570
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.01284,
      "loss": 0.8064,
      "step": 3580
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.01282,
      "loss": 0.9199,
      "step": 3590
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.0128,
      "loss": 0.8622,
      "step": 3600
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.01278,
      "loss": 0.9766,
      "step": 3610
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.01276,
      "loss": 0.9846,
      "step": 3620
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.012740000000000001,
      "loss": 0.815,
      "step": 3630
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.01272,
      "loss": 0.9494,
      "step": 3640
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.012700000000000001,
      "loss": 0.8623,
      "step": 3650
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.01268,
      "loss": 0.7214,
      "step": 3660
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.012660000000000001,
      "loss": 0.6449,
      "step": 3670
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.01264,
      "loss": 0.6023,
      "step": 3680
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.012620000000000001,
      "loss": 0.6038,
      "step": 3690
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.0126,
      "loss": 0.5872,
      "step": 3700
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.012580000000000001,
      "loss": 0.6612,
      "step": 3710
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.01256,
      "loss": 0.6344,
      "step": 3720
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.01254,
      "loss": 0.6095,
      "step": 3730
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.01252,
      "loss": 0.6714,
      "step": 3740
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.0125,
      "loss": 0.603,
      "step": 3750
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.01248,
      "loss": 0.7103,
      "step": 3760
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.01246,
      "loss": 0.6987,
      "step": 3770
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.01244,
      "loss": 0.5912,
      "step": 3780
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.01242,
      "loss": 0.6606,
      "step": 3790
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.0124,
      "loss": 0.6363,
      "step": 3800
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.01238,
      "loss": 0.6352,
      "step": 3810
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.01236,
      "loss": 0.6554,
      "step": 3820
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.01234,
      "loss": 0.6951,
      "step": 3830
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.01232,
      "loss": 0.6683,
      "step": 3840
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.0123,
      "loss": 0.723,
      "step": 3850
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.01228,
      "loss": 0.6373,
      "step": 3860
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.01226,
      "loss": 0.7044,
      "step": 3870
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.012240000000000001,
      "loss": 0.6634,
      "step": 3880
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.01222,
      "loss": 0.6605,
      "step": 3890
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.0122,
      "loss": 0.7106,
      "step": 3900
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.01218,
      "loss": 0.6182,
      "step": 3910
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.01216,
      "loss": 0.6809,
      "step": 3920
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.01214,
      "loss": 0.6352,
      "step": 3930
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.01212,
      "loss": 0.6011,
      "step": 3940
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.0121,
      "loss": 0.632,
      "step": 3950
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.01208,
      "loss": 0.7384,
      "step": 3960
    },
    {
      "epoch": 4.35,
      "learning_rate": 0.01206,
      "loss": 0.6678,
      "step": 3970
    },
    {
      "epoch": 4.36,
      "learning_rate": 0.01204,
      "loss": 0.7098,
      "step": 3980
    },
    {
      "epoch": 4.37,
      "learning_rate": 0.01202,
      "loss": 0.6903,
      "step": 3990
    },
    {
      "epoch": 4.38,
      "learning_rate": 0.012,
      "loss": 0.6494,
      "step": 4000
    },
    {
      "epoch": 4.39,
      "learning_rate": 0.01198,
      "loss": 0.5835,
      "step": 4010
    },
    {
      "epoch": 4.4,
      "learning_rate": 0.01196,
      "loss": 0.6441,
      "step": 4020
    },
    {
      "epoch": 4.41,
      "learning_rate": 0.01194,
      "loss": 0.7247,
      "step": 4030
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.01192,
      "loss": 0.6364,
      "step": 4040
    },
    {
      "epoch": 4.43,
      "learning_rate": 0.011899999999999999,
      "loss": 0.7099,
      "step": 4050
    },
    {
      "epoch": 4.44,
      "learning_rate": 0.01188,
      "loss": 0.7416,
      "step": 4060
    },
    {
      "epoch": 4.46,
      "learning_rate": 0.011859999999999999,
      "loss": 0.613,
      "step": 4070
    },
    {
      "epoch": 4.47,
      "learning_rate": 0.01184,
      "loss": 0.6427,
      "step": 4080
    },
    {
      "epoch": 4.48,
      "learning_rate": 0.011819999999999999,
      "loss": 0.5718,
      "step": 4090
    },
    {
      "epoch": 4.49,
      "learning_rate": 0.0118,
      "loss": 0.7886,
      "step": 4100
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.011779999999999999,
      "loss": 0.6312,
      "step": 4110
    },
    {
      "epoch": 4.51,
      "learning_rate": 0.01176,
      "loss": 0.7444,
      "step": 4120
    },
    {
      "epoch": 4.52,
      "learning_rate": 0.01174,
      "loss": 0.7081,
      "step": 4130
    },
    {
      "epoch": 4.53,
      "learning_rate": 0.01172,
      "loss": 0.654,
      "step": 4140
    },
    {
      "epoch": 4.54,
      "learning_rate": 0.0117,
      "loss": 0.6527,
      "step": 4150
    },
    {
      "epoch": 4.55,
      "learning_rate": 0.01168,
      "loss": 0.663,
      "step": 4160
    },
    {
      "epoch": 4.56,
      "learning_rate": 0.01166,
      "loss": 0.6699,
      "step": 4170
    },
    {
      "epoch": 4.58,
      "learning_rate": 0.01164,
      "loss": 0.7647,
      "step": 4180
    },
    {
      "epoch": 4.59,
      "learning_rate": 0.01162,
      "loss": 0.6607,
      "step": 4190
    },
    {
      "epoch": 4.6,
      "learning_rate": 0.0116,
      "loss": 0.7074,
      "step": 4200
    },
    {
      "epoch": 4.61,
      "learning_rate": 0.01158,
      "loss": 0.6754,
      "step": 4210
    },
    {
      "epoch": 4.62,
      "learning_rate": 0.011559999999999999,
      "loss": 0.6402,
      "step": 4220
    },
    {
      "epoch": 4.63,
      "learning_rate": 0.01154,
      "loss": 0.6189,
      "step": 4230
    },
    {
      "epoch": 4.64,
      "learning_rate": 0.011519999999999999,
      "loss": 0.7313,
      "step": 4240
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.0115,
      "loss": 0.6628,
      "step": 4250
    },
    {
      "epoch": 4.66,
      "learning_rate": 0.011479999999999999,
      "loss": 0.634,
      "step": 4260
    },
    {
      "epoch": 4.67,
      "learning_rate": 0.01146,
      "loss": 0.6379,
      "step": 4270
    },
    {
      "epoch": 4.69,
      "learning_rate": 0.011439999999999999,
      "loss": 0.6465,
      "step": 4280
    },
    {
      "epoch": 4.7,
      "learning_rate": 0.01142,
      "loss": 0.7599,
      "step": 4290
    },
    {
      "epoch": 4.71,
      "learning_rate": 0.011399999999999999,
      "loss": 0.7029,
      "step": 4300
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.01138,
      "loss": 0.7808,
      "step": 4310
    },
    {
      "epoch": 4.73,
      "learning_rate": 0.011359999999999999,
      "loss": 0.6125,
      "step": 4320
    },
    {
      "epoch": 4.74,
      "learning_rate": 0.01134,
      "loss": 0.7636,
      "step": 4330
    },
    {
      "epoch": 4.75,
      "learning_rate": 0.011319999999999998,
      "loss": 0.662,
      "step": 4340
    },
    {
      "epoch": 4.76,
      "learning_rate": 0.0113,
      "loss": 0.7036,
      "step": 4350
    },
    {
      "epoch": 4.77,
      "learning_rate": 0.011279999999999998,
      "loss": 0.6214,
      "step": 4360
    },
    {
      "epoch": 4.78,
      "learning_rate": 0.01126,
      "loss": 0.7095,
      "step": 4370
    },
    {
      "epoch": 4.79,
      "learning_rate": 0.011240000000000002,
      "loss": 0.7466,
      "step": 4380
    },
    {
      "epoch": 4.81,
      "learning_rate": 0.01122,
      "loss": 0.6954,
      "step": 4390
    },
    {
      "epoch": 4.82,
      "learning_rate": 0.011200000000000002,
      "loss": 0.719,
      "step": 4400
    },
    {
      "epoch": 4.83,
      "learning_rate": 0.01118,
      "loss": 0.6287,
      "step": 4410
    },
    {
      "epoch": 4.84,
      "learning_rate": 0.011160000000000002,
      "loss": 0.6171,
      "step": 4420
    },
    {
      "epoch": 4.85,
      "learning_rate": 0.01114,
      "loss": 0.7444,
      "step": 4430
    },
    {
      "epoch": 4.86,
      "learning_rate": 0.011120000000000001,
      "loss": 0.7606,
      "step": 4440
    },
    {
      "epoch": 4.87,
      "learning_rate": 0.0111,
      "loss": 0.6193,
      "step": 4450
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.011080000000000001,
      "loss": 0.7215,
      "step": 4460
    },
    {
      "epoch": 4.89,
      "learning_rate": 0.01106,
      "loss": 0.763,
      "step": 4470
    },
    {
      "epoch": 4.9,
      "learning_rate": 0.011040000000000001,
      "loss": 0.6546,
      "step": 4480
    },
    {
      "epoch": 4.92,
      "learning_rate": 0.01102,
      "loss": 0.6711,
      "step": 4490
    },
    {
      "epoch": 4.93,
      "learning_rate": 0.011000000000000001,
      "loss": 0.6745,
      "step": 4500
    },
    {
      "epoch": 4.94,
      "learning_rate": 0.010980000000000002,
      "loss": 0.6713,
      "step": 4510
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.010960000000000001,
      "loss": 0.6697,
      "step": 4520
    },
    {
      "epoch": 4.96,
      "learning_rate": 0.010940000000000002,
      "loss": 0.7248,
      "step": 4530
    },
    {
      "epoch": 4.97,
      "learning_rate": 0.010920000000000001,
      "loss": 0.688,
      "step": 4540
    },
    {
      "epoch": 4.98,
      "learning_rate": 0.010900000000000002,
      "loss": 0.7487,
      "step": 4550
    },
    {
      "epoch": 4.99,
      "learning_rate": 0.01088,
      "loss": 0.615,
      "step": 4560
    },
    {
      "epoch": 5.0,
      "learning_rate": 0.010860000000000002,
      "loss": 0.6474,
      "step": 4570
    },
    {
      "epoch": 5.01,
      "learning_rate": 0.01084,
      "loss": 0.4539,
      "step": 4580
    },
    {
      "epoch": 5.02,
      "learning_rate": 0.010820000000000001,
      "loss": 0.455,
      "step": 4590
    },
    {
      "epoch": 5.04,
      "learning_rate": 0.0108,
      "loss": 0.4796,
      "step": 4600
    },
    {
      "epoch": 5.05,
      "learning_rate": 0.010780000000000001,
      "loss": 0.4906,
      "step": 4610
    },
    {
      "epoch": 5.06,
      "learning_rate": 0.01076,
      "loss": 0.4685,
      "step": 4620
    },
    {
      "epoch": 5.07,
      "learning_rate": 0.010740000000000001,
      "loss": 0.55,
      "step": 4630
    },
    {
      "epoch": 5.08,
      "learning_rate": 0.01072,
      "loss": 0.5497,
      "step": 4640
    },
    {
      "epoch": 5.09,
      "learning_rate": 0.010700000000000001,
      "loss": 0.5405,
      "step": 4650
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.01068,
      "loss": 0.4448,
      "step": 4660
    },
    {
      "epoch": 5.11,
      "learning_rate": 0.010660000000000001,
      "loss": 0.5154,
      "step": 4670
    },
    {
      "epoch": 5.12,
      "learning_rate": 0.01064,
      "loss": 0.4648,
      "step": 4680
    },
    {
      "epoch": 5.13,
      "learning_rate": 0.010620000000000001,
      "loss": 0.4626,
      "step": 4690
    },
    {
      "epoch": 5.15,
      "learning_rate": 0.0106,
      "loss": 0.5005,
      "step": 4700
    },
    {
      "epoch": 5.16,
      "learning_rate": 0.01058,
      "loss": 0.5048,
      "step": 4710
    },
    {
      "epoch": 5.17,
      "learning_rate": 0.01056,
      "loss": 0.4596,
      "step": 4720
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.01054,
      "loss": 0.4917,
      "step": 4730
    },
    {
      "epoch": 5.19,
      "learning_rate": 0.01052,
      "loss": 0.5254,
      "step": 4740
    },
    {
      "epoch": 5.2,
      "learning_rate": 0.0105,
      "loss": 0.4544,
      "step": 4750
    },
    {
      "epoch": 5.21,
      "learning_rate": 0.010480000000000001,
      "loss": 0.4493,
      "step": 4760
    },
    {
      "epoch": 5.22,
      "learning_rate": 0.01046,
      "loss": 0.4718,
      "step": 4770
    },
    {
      "epoch": 5.23,
      "learning_rate": 0.010440000000000001,
      "loss": 0.5125,
      "step": 4780
    },
    {
      "epoch": 5.24,
      "learning_rate": 0.01042,
      "loss": 0.4738,
      "step": 4790
    },
    {
      "epoch": 5.25,
      "learning_rate": 0.010400000000000001,
      "loss": 0.5232,
      "step": 4800
    },
    {
      "epoch": 5.27,
      "learning_rate": 0.01038,
      "loss": 0.4867,
      "step": 4810
    },
    {
      "epoch": 5.28,
      "learning_rate": 0.010360000000000001,
      "loss": 0.4912,
      "step": 4820
    },
    {
      "epoch": 5.29,
      "learning_rate": 0.01034,
      "loss": 0.5126,
      "step": 4830
    },
    {
      "epoch": 5.3,
      "learning_rate": 0.010320000000000001,
      "loss": 0.473,
      "step": 4840
    },
    {
      "epoch": 5.31,
      "learning_rate": 0.0103,
      "loss": 0.5344,
      "step": 4850
    },
    {
      "epoch": 5.32,
      "learning_rate": 0.010280000000000001,
      "loss": 0.4849,
      "step": 4860
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.01026,
      "loss": 0.5059,
      "step": 4870
    },
    {
      "epoch": 5.34,
      "learning_rate": 0.01024,
      "loss": 0.455,
      "step": 4880
    },
    {
      "epoch": 5.35,
      "learning_rate": 0.01022,
      "loss": 0.4958,
      "step": 4890
    },
    {
      "epoch": 5.36,
      "learning_rate": 0.0102,
      "loss": 0.4406,
      "step": 4900
    },
    {
      "epoch": 5.37,
      "learning_rate": 0.01018,
      "loss": 0.4583,
      "step": 4910
    },
    {
      "epoch": 5.39,
      "learning_rate": 0.01016,
      "loss": 0.4264,
      "step": 4920
    },
    {
      "epoch": 5.4,
      "learning_rate": 0.01014,
      "loss": 0.5197,
      "step": 4930
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.01012,
      "loss": 0.4624,
      "step": 4940
    },
    {
      "epoch": 5.42,
      "learning_rate": 0.0101,
      "loss": 0.5265,
      "step": 4950
    },
    {
      "epoch": 5.43,
      "learning_rate": 0.01008,
      "loss": 0.5077,
      "step": 4960
    },
    {
      "epoch": 5.44,
      "learning_rate": 0.01006,
      "loss": 0.5047,
      "step": 4970
    },
    {
      "epoch": 5.45,
      "learning_rate": 0.01004,
      "loss": 0.5856,
      "step": 4980
    },
    {
      "epoch": 5.46,
      "learning_rate": 0.01002,
      "loss": 0.5455,
      "step": 4990
    },
    {
      "epoch": 5.47,
      "learning_rate": 0.01,
      "loss": 0.5176,
      "step": 5000
    },
    {
      "epoch": 5.48,
      "learning_rate": 0.009980000000000001,
      "loss": 0.5484,
      "step": 5010
    },
    {
      "epoch": 5.5,
      "learning_rate": 0.00996,
      "loss": 0.509,
      "step": 5020
    },
    {
      "epoch": 5.51,
      "learning_rate": 0.009940000000000001,
      "loss": 0.5308,
      "step": 5030
    },
    {
      "epoch": 5.52,
      "learning_rate": 0.00992,
      "loss": 0.5691,
      "step": 5040
    },
    {
      "epoch": 5.53,
      "learning_rate": 0.0099,
      "loss": 0.5782,
      "step": 5050
    },
    {
      "epoch": 5.54,
      "learning_rate": 0.00988,
      "loss": 0.5689,
      "step": 5060
    },
    {
      "epoch": 5.55,
      "learning_rate": 0.00986,
      "loss": 0.4433,
      "step": 5070
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.00984,
      "loss": 0.5699,
      "step": 5080
    },
    {
      "epoch": 5.57,
      "learning_rate": 0.00982,
      "loss": 0.4616,
      "step": 5090
    },
    {
      "epoch": 5.58,
      "learning_rate": 0.0098,
      "loss": 0.49,
      "step": 5100
    },
    {
      "epoch": 5.59,
      "learning_rate": 0.00978,
      "loss": 0.5004,
      "step": 5110
    },
    {
      "epoch": 5.6,
      "learning_rate": 0.00976,
      "loss": 0.5075,
      "step": 5120
    },
    {
      "epoch": 5.62,
      "learning_rate": 0.00974,
      "loss": 0.58,
      "step": 5130
    },
    {
      "epoch": 5.63,
      "learning_rate": 0.00972,
      "loss": 0.4687,
      "step": 5140
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.0097,
      "loss": 0.5667,
      "step": 5150
    },
    {
      "epoch": 5.65,
      "learning_rate": 0.00968,
      "loss": 0.4659,
      "step": 5160
    },
    {
      "epoch": 5.66,
      "learning_rate": 0.00966,
      "loss": 0.5106,
      "step": 5170
    },
    {
      "epoch": 5.67,
      "learning_rate": 0.00964,
      "loss": 0.5104,
      "step": 5180
    },
    {
      "epoch": 5.68,
      "learning_rate": 0.00962,
      "loss": 0.4969,
      "step": 5190
    },
    {
      "epoch": 5.69,
      "learning_rate": 0.0096,
      "loss": 0.5164,
      "step": 5200
    },
    {
      "epoch": 5.7,
      "learning_rate": 0.00958,
      "loss": 0.5605,
      "step": 5210
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.009559999999999999,
      "loss": 0.5448,
      "step": 5220
    },
    {
      "epoch": 5.73,
      "learning_rate": 0.00954,
      "loss": 0.4944,
      "step": 5230
    },
    {
      "epoch": 5.74,
      "learning_rate": 0.009519999999999999,
      "loss": 0.4903,
      "step": 5240
    },
    {
      "epoch": 5.75,
      "learning_rate": 0.0095,
      "loss": 0.6751,
      "step": 5250
    },
    {
      "epoch": 5.76,
      "learning_rate": 0.00948,
      "loss": 0.478,
      "step": 5260
    },
    {
      "epoch": 5.77,
      "learning_rate": 0.00946,
      "loss": 0.4946,
      "step": 5270
    },
    {
      "epoch": 5.78,
      "learning_rate": 0.00944,
      "loss": 0.5611,
      "step": 5280
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.00942,
      "loss": 0.5,
      "step": 5290
    },
    {
      "epoch": 5.8,
      "learning_rate": 0.0094,
      "loss": 0.5268,
      "step": 5300
    },
    {
      "epoch": 5.81,
      "learning_rate": 0.00938,
      "loss": 0.5458,
      "step": 5310
    },
    {
      "epoch": 5.82,
      "learning_rate": 0.00936,
      "loss": 0.5139,
      "step": 5320
    },
    {
      "epoch": 5.83,
      "learning_rate": 0.009340000000000001,
      "loss": 0.56,
      "step": 5330
    },
    {
      "epoch": 5.85,
      "learning_rate": 0.00932,
      "loss": 0.5531,
      "step": 5340
    },
    {
      "epoch": 5.86,
      "learning_rate": 0.009300000000000001,
      "loss": 0.526,
      "step": 5350
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.00928,
      "loss": 0.5445,
      "step": 5360
    },
    {
      "epoch": 5.88,
      "learning_rate": 0.009260000000000001,
      "loss": 0.5096,
      "step": 5370
    },
    {
      "epoch": 5.89,
      "learning_rate": 0.00924,
      "loss": 0.5388,
      "step": 5380
    },
    {
      "epoch": 5.9,
      "learning_rate": 0.00922,
      "loss": 0.5285,
      "step": 5390
    },
    {
      "epoch": 5.91,
      "learning_rate": 0.0092,
      "loss": 0.5361,
      "step": 5400
    },
    {
      "epoch": 5.92,
      "learning_rate": 0.00918,
      "loss": 0.5087,
      "step": 5410
    },
    {
      "epoch": 5.93,
      "learning_rate": 0.00916,
      "loss": 0.5665,
      "step": 5420
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.00914,
      "loss": 0.5041,
      "step": 5430
    },
    {
      "epoch": 5.96,
      "learning_rate": 0.009120000000000001,
      "loss": 0.5427,
      "step": 5440
    },
    {
      "epoch": 5.97,
      "learning_rate": 0.0091,
      "loss": 0.5995,
      "step": 5450
    },
    {
      "epoch": 5.98,
      "learning_rate": 0.009080000000000001,
      "loss": 0.5724,
      "step": 5460
    },
    {
      "epoch": 5.99,
      "learning_rate": 0.00906,
      "loss": 0.499,
      "step": 5470
    },
    {
      "epoch": 6.0,
      "learning_rate": 0.009040000000000001,
      "loss": 0.5456,
      "step": 5480
    },
    {
      "epoch": 6.01,
      "learning_rate": 0.00902,
      "loss": 0.3691,
      "step": 5490
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.009000000000000001,
      "loss": 0.3792,
      "step": 5500
    },
    {
      "epoch": 6.03,
      "learning_rate": 0.00898,
      "loss": 0.3363,
      "step": 5510
    },
    {
      "epoch": 6.04,
      "learning_rate": 0.008960000000000001,
      "loss": 0.3765,
      "step": 5520
    },
    {
      "epoch": 6.05,
      "learning_rate": 0.00894,
      "loss": 0.4366,
      "step": 5530
    },
    {
      "epoch": 6.06,
      "learning_rate": 0.00892,
      "loss": 0.3472,
      "step": 5540
    },
    {
      "epoch": 6.08,
      "learning_rate": 0.0089,
      "loss": 0.3643,
      "step": 5550
    },
    {
      "epoch": 6.09,
      "learning_rate": 0.00888,
      "loss": 0.4013,
      "step": 5560
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.00886,
      "loss": 0.3446,
      "step": 5570
    },
    {
      "epoch": 6.11,
      "learning_rate": 0.00884,
      "loss": 0.3475,
      "step": 5580
    },
    {
      "epoch": 6.12,
      "learning_rate": 0.00882,
      "loss": 0.3567,
      "step": 5590
    },
    {
      "epoch": 6.13,
      "learning_rate": 0.0088,
      "loss": 0.3314,
      "step": 5600
    },
    {
      "epoch": 6.14,
      "learning_rate": 0.00878,
      "loss": 0.3877,
      "step": 5610
    },
    {
      "epoch": 6.15,
      "learning_rate": 0.00876,
      "loss": 0.4031,
      "step": 5620
    },
    {
      "epoch": 6.16,
      "learning_rate": 0.00874,
      "loss": 0.3551,
      "step": 5630
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.00872,
      "loss": 0.3827,
      "step": 5640
    },
    {
      "epoch": 6.19,
      "learning_rate": 0.0087,
      "loss": 0.3654,
      "step": 5650
    },
    {
      "epoch": 6.2,
      "learning_rate": 0.00868,
      "loss": 0.3878,
      "step": 5660
    },
    {
      "epoch": 6.21,
      "learning_rate": 0.00866,
      "loss": 0.3712,
      "step": 5670
    },
    {
      "epoch": 6.22,
      "learning_rate": 0.00864,
      "loss": 0.456,
      "step": 5680
    },
    {
      "epoch": 6.23,
      "learning_rate": 0.008620000000000001,
      "loss": 0.3985,
      "step": 5690
    },
    {
      "epoch": 6.24,
      "learning_rate": 0.0086,
      "loss": 0.4058,
      "step": 5700
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.00858,
      "loss": 0.3761,
      "step": 5710
    },
    {
      "epoch": 6.26,
      "learning_rate": 0.00856,
      "loss": 0.386,
      "step": 5720
    },
    {
      "epoch": 6.27,
      "learning_rate": 0.00854,
      "loss": 0.3291,
      "step": 5730
    },
    {
      "epoch": 6.28,
      "learning_rate": 0.00852,
      "loss": 0.341,
      "step": 5740
    },
    {
      "epoch": 6.29,
      "learning_rate": 0.0085,
      "loss": 0.3682,
      "step": 5750
    },
    {
      "epoch": 6.31,
      "learning_rate": 0.00848,
      "loss": 0.3573,
      "step": 5760
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.00846,
      "loss": 0.3638,
      "step": 5770
    },
    {
      "epoch": 6.33,
      "learning_rate": 0.00844,
      "loss": 0.359,
      "step": 5780
    },
    {
      "epoch": 6.34,
      "learning_rate": 0.00842,
      "loss": 0.3501,
      "step": 5790
    },
    {
      "epoch": 6.35,
      "learning_rate": 0.0084,
      "loss": 0.3907,
      "step": 5800
    },
    {
      "epoch": 6.36,
      "learning_rate": 0.00838,
      "loss": 0.3806,
      "step": 5810
    },
    {
      "epoch": 6.37,
      "learning_rate": 0.00836,
      "loss": 0.3621,
      "step": 5820
    },
    {
      "epoch": 6.38,
      "learning_rate": 0.00834,
      "loss": 0.4481,
      "step": 5830
    },
    {
      "epoch": 6.39,
      "learning_rate": 0.00832,
      "loss": 0.3867,
      "step": 5840
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.0083,
      "loss": 0.4113,
      "step": 5850
    },
    {
      "epoch": 6.41,
      "learning_rate": 0.00828,
      "loss": 0.3557,
      "step": 5860
    },
    {
      "epoch": 6.43,
      "learning_rate": 0.00826,
      "loss": 0.3886,
      "step": 5870
    },
    {
      "epoch": 6.44,
      "learning_rate": 0.008239999999999999,
      "loss": 0.3881,
      "step": 5880
    },
    {
      "epoch": 6.45,
      "learning_rate": 0.00822,
      "loss": 0.3997,
      "step": 5890
    },
    {
      "epoch": 6.46,
      "learning_rate": 0.008199999999999999,
      "loss": 0.391,
      "step": 5900
    },
    {
      "epoch": 6.47,
      "learning_rate": 0.00818,
      "loss": 0.4257,
      "step": 5910
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.008159999999999999,
      "loss": 0.3865,
      "step": 5920
    },
    {
      "epoch": 6.49,
      "learning_rate": 0.00814,
      "loss": 0.3941,
      "step": 5930
    },
    {
      "epoch": 6.5,
      "learning_rate": 0.00812,
      "loss": 0.3946,
      "step": 5940
    },
    {
      "epoch": 6.51,
      "learning_rate": 0.008100000000000001,
      "loss": 0.3961,
      "step": 5950
    },
    {
      "epoch": 6.52,
      "learning_rate": 0.00808,
      "loss": 0.3966,
      "step": 5960
    },
    {
      "epoch": 6.54,
      "learning_rate": 0.008060000000000001,
      "loss": 0.3551,
      "step": 5970
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.00804,
      "loss": 0.3396,
      "step": 5980
    },
    {
      "epoch": 6.56,
      "learning_rate": 0.008020000000000001,
      "loss": 0.4005,
      "step": 5990
    },
    {
      "epoch": 6.57,
      "learning_rate": 0.008,
      "loss": 0.3865,
      "step": 6000
    },
    {
      "epoch": 6.58,
      "learning_rate": 0.007980000000000001,
      "loss": 0.3869,
      "step": 6010
    },
    {
      "epoch": 6.59,
      "learning_rate": 0.00796,
      "loss": 0.3706,
      "step": 6020
    },
    {
      "epoch": 6.6,
      "learning_rate": 0.007940000000000001,
      "loss": 0.4493,
      "step": 6030
    },
    {
      "epoch": 6.61,
      "learning_rate": 0.00792,
      "loss": 0.4048,
      "step": 6040
    },
    {
      "epoch": 6.62,
      "learning_rate": 0.0079,
      "loss": 0.3712,
      "step": 6050
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.00788,
      "loss": 0.3897,
      "step": 6060
    },
    {
      "epoch": 6.64,
      "learning_rate": 0.00786,
      "loss": 0.4221,
      "step": 6070
    },
    {
      "epoch": 6.66,
      "learning_rate": 0.00784,
      "loss": 0.365,
      "step": 6080
    },
    {
      "epoch": 6.67,
      "learning_rate": 0.00782,
      "loss": 0.4427,
      "step": 6090
    },
    {
      "epoch": 6.68,
      "learning_rate": 0.0078000000000000005,
      "loss": 0.4125,
      "step": 6100
    },
    {
      "epoch": 6.69,
      "learning_rate": 0.0077800000000000005,
      "loss": 0.4288,
      "step": 6110
    },
    {
      "epoch": 6.7,
      "learning_rate": 0.00776,
      "loss": 0.4055,
      "step": 6120
    },
    {
      "epoch": 6.71,
      "learning_rate": 0.00774,
      "loss": 0.4014,
      "step": 6130
    },
    {
      "epoch": 6.72,
      "learning_rate": 0.00772,
      "loss": 0.4681,
      "step": 6140
    },
    {
      "epoch": 6.73,
      "learning_rate": 0.0077,
      "loss": 0.4066,
      "step": 6150
    },
    {
      "epoch": 6.74,
      "learning_rate": 0.00768,
      "loss": 0.3488,
      "step": 6160
    },
    {
      "epoch": 6.75,
      "learning_rate": 0.00766,
      "loss": 0.411,
      "step": 6170
    },
    {
      "epoch": 6.77,
      "learning_rate": 0.00764,
      "loss": 0.3413,
      "step": 6180
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.00762,
      "loss": 0.3562,
      "step": 6190
    },
    {
      "epoch": 6.79,
      "learning_rate": 0.0076,
      "loss": 0.4029,
      "step": 6200
    },
    {
      "epoch": 6.8,
      "learning_rate": 0.00758,
      "loss": 0.4086,
      "step": 6210
    },
    {
      "epoch": 6.81,
      "learning_rate": 0.00756,
      "loss": 0.3925,
      "step": 6220
    },
    {
      "epoch": 6.82,
      "learning_rate": 0.00754,
      "loss": 0.4413,
      "step": 6230
    },
    {
      "epoch": 6.83,
      "learning_rate": 0.00752,
      "loss": 0.3779,
      "step": 6240
    },
    {
      "epoch": 6.84,
      "learning_rate": 0.0075,
      "loss": 0.4066,
      "step": 6250
    },
    {
      "epoch": 6.85,
      "learning_rate": 0.0074800000000000005,
      "loss": 0.4014,
      "step": 6260
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.0074600000000000005,
      "loss": 0.3627,
      "step": 6270
    },
    {
      "epoch": 6.87,
      "learning_rate": 0.00744,
      "loss": 0.4064,
      "step": 6280
    },
    {
      "epoch": 6.89,
      "learning_rate": 0.00742,
      "loss": 0.4105,
      "step": 6290
    },
    {
      "epoch": 6.9,
      "learning_rate": 0.0074,
      "loss": 0.3683,
      "step": 6300
    },
    {
      "epoch": 6.91,
      "learning_rate": 0.00738,
      "loss": 0.3701,
      "step": 6310
    },
    {
      "epoch": 6.92,
      "learning_rate": 0.00736,
      "loss": 0.4322,
      "step": 6320
    },
    {
      "epoch": 6.93,
      "learning_rate": 0.00734,
      "loss": 0.3775,
      "step": 6330
    },
    {
      "epoch": 6.94,
      "learning_rate": 0.00732,
      "loss": 0.4346,
      "step": 6340
    },
    {
      "epoch": 6.95,
      "learning_rate": 0.0073,
      "loss": 0.4074,
      "step": 6350
    },
    {
      "epoch": 6.96,
      "learning_rate": 0.00728,
      "loss": 0.4172,
      "step": 6360
    },
    {
      "epoch": 6.97,
      "learning_rate": 0.00726,
      "loss": 0.3913,
      "step": 6370
    },
    {
      "epoch": 6.98,
      "learning_rate": 0.00724,
      "loss": 0.4313,
      "step": 6380
    },
    {
      "epoch": 7.0,
      "learning_rate": 0.00722,
      "loss": 0.4137,
      "step": 6390
    },
    {
      "epoch": 7.01,
      "learning_rate": 0.0072,
      "loss": 0.3177,
      "step": 6400
    },
    {
      "epoch": 7.02,
      "learning_rate": 0.00718,
      "loss": 0.2816,
      "step": 6410
    },
    {
      "epoch": 7.03,
      "learning_rate": 0.00716,
      "loss": 0.314,
      "step": 6420
    },
    {
      "epoch": 7.04,
      "learning_rate": 0.00714,
      "loss": 0.2749,
      "step": 6430
    },
    {
      "epoch": 7.05,
      "learning_rate": 0.00712,
      "loss": 0.2551,
      "step": 6440
    },
    {
      "epoch": 7.06,
      "learning_rate": 0.0070999999999999995,
      "loss": 0.2811,
      "step": 6450
    },
    {
      "epoch": 7.07,
      "learning_rate": 0.0070799999999999995,
      "loss": 0.3144,
      "step": 6460
    },
    {
      "epoch": 7.08,
      "learning_rate": 0.0070599999999999994,
      "loss": 0.3231,
      "step": 6470
    },
    {
      "epoch": 7.09,
      "learning_rate": 0.007039999999999999,
      "loss": 0.2903,
      "step": 6480
    },
    {
      "epoch": 7.1,
      "learning_rate": 0.007019999999999999,
      "loss": 0.2888,
      "step": 6490
    },
    {
      "epoch": 7.12,
      "learning_rate": 0.006999999999999999,
      "loss": 0.2938,
      "step": 6500
    },
    {
      "epoch": 7.13,
      "learning_rate": 0.00698,
      "loss": 0.2657,
      "step": 6510
    },
    {
      "epoch": 7.14,
      "learning_rate": 0.00696,
      "loss": 0.2749,
      "step": 6520
    },
    {
      "epoch": 7.15,
      "learning_rate": 0.00694,
      "loss": 0.3205,
      "step": 6530
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.00692,
      "loss": 0.2636,
      "step": 6540
    },
    {
      "epoch": 7.17,
      "learning_rate": 0.0069,
      "loss": 0.2965,
      "step": 6550
    },
    {
      "epoch": 7.18,
      "learning_rate": 0.00688,
      "loss": 0.3107,
      "step": 6560
    },
    {
      "epoch": 7.19,
      "learning_rate": 0.006860000000000001,
      "loss": 0.2868,
      "step": 6570
    },
    {
      "epoch": 7.2,
      "learning_rate": 0.006840000000000001,
      "loss": 0.2884,
      "step": 6580
    },
    {
      "epoch": 7.21,
      "learning_rate": 0.0068200000000000005,
      "loss": 0.3167,
      "step": 6590
    },
    {
      "epoch": 7.22,
      "learning_rate": 0.0068000000000000005,
      "loss": 0.2895,
      "step": 6600
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.0067800000000000004,
      "loss": 0.2665,
      "step": 6610
    },
    {
      "epoch": 7.25,
      "learning_rate": 0.00676,
      "loss": 0.2712,
      "step": 6620
    },
    {
      "epoch": 7.26,
      "learning_rate": 0.00674,
      "loss": 0.3069,
      "step": 6630
    },
    {
      "epoch": 7.27,
      "learning_rate": 0.00672,
      "loss": 0.2646,
      "step": 6640
    },
    {
      "epoch": 7.28,
      "learning_rate": 0.0067,
      "loss": 0.2744,
      "step": 6650
    },
    {
      "epoch": 7.29,
      "learning_rate": 0.00668,
      "loss": 0.267,
      "step": 6660
    },
    {
      "epoch": 7.3,
      "learning_rate": 0.00666,
      "loss": 0.2705,
      "step": 6670
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.00664,
      "loss": 0.2884,
      "step": 6680
    },
    {
      "epoch": 7.32,
      "learning_rate": 0.006620000000000001,
      "loss": 0.2781,
      "step": 6690
    },
    {
      "epoch": 7.33,
      "learning_rate": 0.006600000000000001,
      "loss": 0.2684,
      "step": 6700
    },
    {
      "epoch": 7.35,
      "learning_rate": 0.006580000000000001,
      "loss": 0.2893,
      "step": 6710
    },
    {
      "epoch": 7.36,
      "learning_rate": 0.006560000000000001,
      "loss": 0.2813,
      "step": 6720
    },
    {
      "epoch": 7.37,
      "learning_rate": 0.006540000000000001,
      "loss": 0.2626,
      "step": 6730
    },
    {
      "epoch": 7.38,
      "learning_rate": 0.006520000000000001,
      "loss": 0.3116,
      "step": 6740
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.006500000000000001,
      "loss": 0.2694,
      "step": 6750
    },
    {
      "epoch": 7.4,
      "learning_rate": 0.0064800000000000005,
      "loss": 0.3339,
      "step": 6760
    },
    {
      "epoch": 7.41,
      "learning_rate": 0.0064600000000000005,
      "loss": 0.2653,
      "step": 6770
    },
    {
      "epoch": 7.42,
      "learning_rate": 0.00644,
      "loss": 0.3137,
      "step": 6780
    },
    {
      "epoch": 7.43,
      "learning_rate": 0.00642,
      "loss": 0.3086,
      "step": 6790
    },
    {
      "epoch": 7.44,
      "learning_rate": 0.0064,
      "loss": 0.313,
      "step": 6800
    },
    {
      "epoch": 7.45,
      "learning_rate": 0.00638,
      "loss": 0.2737,
      "step": 6810
    },
    {
      "epoch": 7.47,
      "learning_rate": 0.00636,
      "loss": 0.2872,
      "step": 6820
    },
    {
      "epoch": 7.48,
      "learning_rate": 0.00634,
      "loss": 0.2904,
      "step": 6830
    },
    {
      "epoch": 7.49,
      "learning_rate": 0.00632,
      "loss": 0.3122,
      "step": 6840
    },
    {
      "epoch": 7.5,
      "learning_rate": 0.0063,
      "loss": 0.3051,
      "step": 6850
    },
    {
      "epoch": 7.51,
      "learning_rate": 0.00628,
      "loss": 0.2984,
      "step": 6860
    },
    {
      "epoch": 7.52,
      "learning_rate": 0.00626,
      "loss": 0.311,
      "step": 6870
    },
    {
      "epoch": 7.53,
      "learning_rate": 0.00624,
      "loss": 0.3032,
      "step": 6880
    },
    {
      "epoch": 7.54,
      "learning_rate": 0.00622,
      "loss": 0.3111,
      "step": 6890
    },
    {
      "epoch": 7.55,
      "learning_rate": 0.0062,
      "loss": 0.3004,
      "step": 6900
    },
    {
      "epoch": 7.56,
      "learning_rate": 0.00618,
      "loss": 0.2894,
      "step": 6910
    },
    {
      "epoch": 7.58,
      "learning_rate": 0.00616,
      "loss": 0.2744,
      "step": 6920
    },
    {
      "epoch": 7.59,
      "learning_rate": 0.00614,
      "loss": 0.254,
      "step": 6930
    },
    {
      "epoch": 7.6,
      "learning_rate": 0.0061200000000000004,
      "loss": 0.3362,
      "step": 6940
    },
    {
      "epoch": 7.61,
      "learning_rate": 0.0061,
      "loss": 0.2964,
      "step": 6950
    },
    {
      "epoch": 7.62,
      "learning_rate": 0.00608,
      "loss": 0.2681,
      "step": 6960
    },
    {
      "epoch": 7.63,
      "learning_rate": 0.00606,
      "loss": 0.2844,
      "step": 6970
    },
    {
      "epoch": 7.64,
      "learning_rate": 0.00604,
      "loss": 0.3006,
      "step": 6980
    },
    {
      "epoch": 7.65,
      "learning_rate": 0.00602,
      "loss": 0.3092,
      "step": 6990
    },
    {
      "epoch": 7.66,
      "learning_rate": 0.006,
      "loss": 0.2989,
      "step": 7000
    },
    {
      "epoch": 7.67,
      "learning_rate": 0.00598,
      "loss": 0.3292,
      "step": 7010
    },
    {
      "epoch": 7.68,
      "learning_rate": 0.00596,
      "loss": 0.3271,
      "step": 7020
    },
    {
      "epoch": 7.7,
      "learning_rate": 0.00594,
      "loss": 0.2399,
      "step": 7030
    },
    {
      "epoch": 7.71,
      "learning_rate": 0.00592,
      "loss": 0.3341,
      "step": 7040
    },
    {
      "epoch": 7.72,
      "learning_rate": 0.0059,
      "loss": 0.2701,
      "step": 7050
    },
    {
      "epoch": 7.73,
      "learning_rate": 0.00588,
      "loss": 0.2748,
      "step": 7060
    },
    {
      "epoch": 7.74,
      "learning_rate": 0.00586,
      "loss": 0.3163,
      "step": 7070
    },
    {
      "epoch": 7.75,
      "learning_rate": 0.00584,
      "loss": 0.3203,
      "step": 7080
    },
    {
      "epoch": 7.76,
      "learning_rate": 0.00582,
      "loss": 0.3146,
      "step": 7090
    },
    {
      "epoch": 7.77,
      "learning_rate": 0.0058,
      "loss": 0.2789,
      "step": 7100
    },
    {
      "epoch": 7.78,
      "learning_rate": 0.0057799999999999995,
      "loss": 0.2768,
      "step": 7110
    },
    {
      "epoch": 7.79,
      "learning_rate": 0.0057599999999999995,
      "loss": 0.2612,
      "step": 7120
    },
    {
      "epoch": 7.81,
      "learning_rate": 0.0057399999999999994,
      "loss": 0.2904,
      "step": 7130
    },
    {
      "epoch": 7.82,
      "learning_rate": 0.005719999999999999,
      "loss": 0.3115,
      "step": 7140
    },
    {
      "epoch": 7.83,
      "learning_rate": 0.005699999999999999,
      "loss": 0.2854,
      "step": 7150
    },
    {
      "epoch": 7.84,
      "learning_rate": 0.005679999999999999,
      "loss": 0.2759,
      "step": 7160
    },
    {
      "epoch": 7.85,
      "learning_rate": 0.005659999999999999,
      "loss": 0.33,
      "step": 7170
    },
    {
      "epoch": 7.86,
      "learning_rate": 0.005639999999999999,
      "loss": 0.3006,
      "step": 7180
    },
    {
      "epoch": 7.87,
      "learning_rate": 0.005620000000000001,
      "loss": 0.3259,
      "step": 7190
    },
    {
      "epoch": 7.88,
      "learning_rate": 0.005600000000000001,
      "loss": 0.3116,
      "step": 7200
    },
    {
      "epoch": 7.89,
      "learning_rate": 0.005580000000000001,
      "loss": 0.29,
      "step": 7210
    },
    {
      "epoch": 7.9,
      "learning_rate": 0.005560000000000001,
      "loss": 0.3148,
      "step": 7220
    },
    {
      "epoch": 7.91,
      "learning_rate": 0.005540000000000001,
      "loss": 0.3352,
      "step": 7230
    },
    {
      "epoch": 7.93,
      "learning_rate": 0.005520000000000001,
      "loss": 0.2932,
      "step": 7240
    },
    {
      "epoch": 7.94,
      "learning_rate": 0.0055000000000000005,
      "loss": 0.3148,
      "step": 7250
    },
    {
      "epoch": 7.95,
      "learning_rate": 0.0054800000000000005,
      "loss": 0.2926,
      "step": 7260
    },
    {
      "epoch": 7.96,
      "learning_rate": 0.0054600000000000004,
      "loss": 0.3407,
      "step": 7270
    },
    {
      "epoch": 7.97,
      "learning_rate": 0.00544,
      "loss": 0.3021,
      "step": 7280
    },
    {
      "epoch": 7.98,
      "learning_rate": 0.00542,
      "loss": 0.2859,
      "step": 7290
    },
    {
      "epoch": 7.99,
      "learning_rate": 0.0054,
      "loss": 0.2803,
      "step": 7300
    },
    {
      "epoch": 8.0,
      "learning_rate": 0.00538,
      "loss": 0.2595,
      "step": 7310
    },
    {
      "epoch": 8.01,
      "learning_rate": 0.00536,
      "loss": 0.2265,
      "step": 7320
    },
    {
      "epoch": 8.02,
      "learning_rate": 0.00534,
      "loss": 0.222,
      "step": 7330
    },
    {
      "epoch": 8.04,
      "learning_rate": 0.00532,
      "loss": 0.2414,
      "step": 7340
    },
    {
      "epoch": 8.05,
      "learning_rate": 0.0053,
      "loss": 0.1836,
      "step": 7350
    },
    {
      "epoch": 8.06,
      "learning_rate": 0.00528,
      "loss": 0.2018,
      "step": 7360
    },
    {
      "epoch": 8.07,
      "learning_rate": 0.00526,
      "loss": 0.2075,
      "step": 7370
    },
    {
      "epoch": 8.08,
      "learning_rate": 0.005240000000000001,
      "loss": 0.2254,
      "step": 7380
    },
    {
      "epoch": 8.09,
      "learning_rate": 0.005220000000000001,
      "loss": 0.2134,
      "step": 7390
    },
    {
      "epoch": 8.1,
      "learning_rate": 0.005200000000000001,
      "loss": 0.1934,
      "step": 7400
    },
    {
      "epoch": 8.11,
      "learning_rate": 0.005180000000000001,
      "loss": 0.2278,
      "step": 7410
    },
    {
      "epoch": 8.12,
      "learning_rate": 0.0051600000000000005,
      "loss": 0.2263,
      "step": 7420
    },
    {
      "epoch": 8.13,
      "learning_rate": 0.0051400000000000005,
      "loss": 0.222,
      "step": 7430
    },
    {
      "epoch": 8.14,
      "learning_rate": 0.00512,
      "loss": 0.2418,
      "step": 7440
    },
    {
      "epoch": 8.16,
      "learning_rate": 0.0051,
      "loss": 0.2672,
      "step": 7450
    },
    {
      "epoch": 8.17,
      "learning_rate": 0.00508,
      "loss": 0.2198,
      "step": 7460
    },
    {
      "epoch": 8.18,
      "learning_rate": 0.00506,
      "loss": 0.2327,
      "step": 7470
    },
    {
      "epoch": 8.19,
      "learning_rate": 0.00504,
      "loss": 0.2024,
      "step": 7480
    },
    {
      "epoch": 8.2,
      "learning_rate": 0.00502,
      "loss": 0.212,
      "step": 7490
    },
    {
      "epoch": 8.21,
      "learning_rate": 0.005,
      "loss": 0.2376,
      "step": 7500
    },
    {
      "epoch": 8.22,
      "learning_rate": 0.00498,
      "loss": 0.2084,
      "step": 7510
    },
    {
      "epoch": 8.23,
      "learning_rate": 0.00496,
      "loss": 0.2151,
      "step": 7520
    },
    {
      "epoch": 8.24,
      "learning_rate": 0.00494,
      "loss": 0.2313,
      "step": 7530
    },
    {
      "epoch": 8.25,
      "learning_rate": 0.00492,
      "loss": 0.2433,
      "step": 7540
    },
    {
      "epoch": 8.26,
      "learning_rate": 0.0049,
      "loss": 0.2168,
      "step": 7550
    },
    {
      "epoch": 8.28,
      "learning_rate": 0.00488,
      "loss": 0.2366,
      "step": 7560
    },
    {
      "epoch": 8.29,
      "learning_rate": 0.00486,
      "loss": 0.2272,
      "step": 7570
    },
    {
      "epoch": 8.3,
      "learning_rate": 0.00484,
      "loss": 0.2399,
      "step": 7580
    },
    {
      "epoch": 8.31,
      "learning_rate": 0.00482,
      "loss": 0.2452,
      "step": 7590
    },
    {
      "epoch": 8.32,
      "learning_rate": 0.0048,
      "loss": 0.2289,
      "step": 7600
    },
    {
      "epoch": 8.33,
      "learning_rate": 0.0047799999999999995,
      "loss": 0.2421,
      "step": 7610
    },
    {
      "epoch": 8.34,
      "learning_rate": 0.0047599999999999995,
      "loss": 0.2456,
      "step": 7620
    },
    {
      "epoch": 8.35,
      "learning_rate": 0.00474,
      "loss": 0.2507,
      "step": 7630
    },
    {
      "epoch": 8.36,
      "learning_rate": 0.00472,
      "loss": 0.1895,
      "step": 7640
    },
    {
      "epoch": 8.37,
      "learning_rate": 0.0047,
      "loss": 0.2428,
      "step": 7650
    },
    {
      "epoch": 8.39,
      "learning_rate": 0.00468,
      "loss": 0.2022,
      "step": 7660
    },
    {
      "epoch": 8.4,
      "learning_rate": 0.00466,
      "loss": 0.2287,
      "step": 7670
    },
    {
      "epoch": 8.41,
      "learning_rate": 0.00464,
      "loss": 0.2484,
      "step": 7680
    },
    {
      "epoch": 8.42,
      "learning_rate": 0.00462,
      "loss": 0.2452,
      "step": 7690
    },
    {
      "epoch": 8.43,
      "learning_rate": 0.0046,
      "loss": 0.2335,
      "step": 7700
    },
    {
      "epoch": 8.44,
      "learning_rate": 0.00458,
      "loss": 0.2499,
      "step": 7710
    },
    {
      "epoch": 8.45,
      "learning_rate": 0.004560000000000001,
      "loss": 0.2587,
      "step": 7720
    },
    {
      "epoch": 8.46,
      "learning_rate": 0.004540000000000001,
      "loss": 0.2202,
      "step": 7730
    },
    {
      "epoch": 8.47,
      "learning_rate": 0.004520000000000001,
      "loss": 0.2312,
      "step": 7740
    },
    {
      "epoch": 8.48,
      "learning_rate": 0.0045000000000000005,
      "loss": 0.2079,
      "step": 7750
    },
    {
      "epoch": 8.49,
      "learning_rate": 0.0044800000000000005,
      "loss": 0.2028,
      "step": 7760
    },
    {
      "epoch": 8.51,
      "learning_rate": 0.00446,
      "loss": 0.2344,
      "step": 7770
    },
    {
      "epoch": 8.52,
      "learning_rate": 0.00444,
      "loss": 0.2196,
      "step": 7780
    },
    {
      "epoch": 8.53,
      "learning_rate": 0.00442,
      "loss": 0.2117,
      "step": 7790
    },
    {
      "epoch": 8.54,
      "learning_rate": 0.0044,
      "loss": 0.1991,
      "step": 7800
    },
    {
      "epoch": 8.55,
      "learning_rate": 0.00438,
      "loss": 0.2277,
      "step": 7810
    },
    {
      "epoch": 8.56,
      "learning_rate": 0.00436,
      "loss": 0.2233,
      "step": 7820
    },
    {
      "epoch": 8.57,
      "learning_rate": 0.00434,
      "loss": 0.2234,
      "step": 7830
    },
    {
      "epoch": 8.58,
      "learning_rate": 0.00432,
      "loss": 0.2377,
      "step": 7840
    },
    {
      "epoch": 8.59,
      "learning_rate": 0.0043,
      "loss": 0.2256,
      "step": 7850
    },
    {
      "epoch": 8.6,
      "learning_rate": 0.00428,
      "loss": 0.2151,
      "step": 7860
    },
    {
      "epoch": 8.62,
      "learning_rate": 0.00426,
      "loss": 0.2395,
      "step": 7870
    },
    {
      "epoch": 8.63,
      "learning_rate": 0.00424,
      "loss": 0.2397,
      "step": 7880
    },
    {
      "epoch": 8.64,
      "learning_rate": 0.00422,
      "loss": 0.2411,
      "step": 7890
    },
    {
      "epoch": 8.65,
      "learning_rate": 0.0042,
      "loss": 0.2391,
      "step": 7900
    },
    {
      "epoch": 8.66,
      "learning_rate": 0.00418,
      "loss": 0.202,
      "step": 7910
    },
    {
      "epoch": 8.67,
      "learning_rate": 0.00416,
      "loss": 0.2261,
      "step": 7920
    },
    {
      "epoch": 8.68,
      "learning_rate": 0.00414,
      "loss": 0.2185,
      "step": 7930
    },
    {
      "epoch": 8.69,
      "learning_rate": 0.0041199999999999995,
      "loss": 0.2032,
      "step": 7940
    },
    {
      "epoch": 8.7,
      "learning_rate": 0.0040999999999999995,
      "loss": 0.2295,
      "step": 7950
    },
    {
      "epoch": 8.71,
      "learning_rate": 0.004079999999999999,
      "loss": 0.1962,
      "step": 7960
    },
    {
      "epoch": 8.72,
      "learning_rate": 0.00406,
      "loss": 0.2687,
      "step": 7970
    },
    {
      "epoch": 8.74,
      "learning_rate": 0.00404,
      "loss": 0.2286,
      "step": 7980
    },
    {
      "epoch": 8.75,
      "learning_rate": 0.00402,
      "loss": 0.1866,
      "step": 7990
    },
    {
      "epoch": 8.76,
      "learning_rate": 0.004,
      "loss": 0.2219,
      "step": 8000
    },
    {
      "epoch": 8.77,
      "learning_rate": 0.00398,
      "loss": 0.1913,
      "step": 8010
    },
    {
      "epoch": 8.78,
      "learning_rate": 0.00396,
      "loss": 0.2145,
      "step": 8020
    },
    {
      "epoch": 8.79,
      "learning_rate": 0.00394,
      "loss": 0.2148,
      "step": 8030
    },
    {
      "epoch": 8.8,
      "learning_rate": 0.00392,
      "loss": 0.2323,
      "step": 8040
    },
    {
      "epoch": 8.81,
      "learning_rate": 0.0039000000000000003,
      "loss": 0.2358,
      "step": 8050
    },
    {
      "epoch": 8.82,
      "learning_rate": 0.00388,
      "loss": 0.2347,
      "step": 8060
    },
    {
      "epoch": 8.83,
      "learning_rate": 0.00386,
      "loss": 0.2603,
      "step": 8070
    },
    {
      "epoch": 8.85,
      "learning_rate": 0.00384,
      "loss": 0.2187,
      "step": 8080
    },
    {
      "epoch": 8.86,
      "learning_rate": 0.00382,
      "loss": 0.2091,
      "step": 8090
    },
    {
      "epoch": 8.87,
      "learning_rate": 0.0038,
      "loss": 0.246,
      "step": 8100
    },
    {
      "epoch": 8.88,
      "learning_rate": 0.00378,
      "loss": 0.2096,
      "step": 8110
    },
    {
      "epoch": 8.89,
      "learning_rate": 0.00376,
      "loss": 0.2186,
      "step": 8120
    },
    {
      "epoch": 8.9,
      "learning_rate": 0.0037400000000000003,
      "loss": 0.229,
      "step": 8130
    },
    {
      "epoch": 8.91,
      "learning_rate": 0.00372,
      "loss": 0.2185,
      "step": 8140
    },
    {
      "epoch": 8.92,
      "learning_rate": 0.0037,
      "loss": 0.1984,
      "step": 8150
    },
    {
      "epoch": 8.93,
      "learning_rate": 0.00368,
      "loss": 0.2281,
      "step": 8160
    },
    {
      "epoch": 8.94,
      "learning_rate": 0.00366,
      "loss": 0.2145,
      "step": 8170
    },
    {
      "epoch": 8.95,
      "learning_rate": 0.00364,
      "loss": 0.2391,
      "step": 8180
    },
    {
      "epoch": 8.97,
      "learning_rate": 0.00362,
      "loss": 0.2745,
      "step": 8190
    },
    {
      "epoch": 8.98,
      "learning_rate": 0.0036,
      "loss": 0.2505,
      "step": 8200
    },
    {
      "epoch": 8.99,
      "learning_rate": 0.00358,
      "loss": 0.2116,
      "step": 8210
    },
    {
      "epoch": 9.0,
      "learning_rate": 0.00356,
      "loss": 0.2334,
      "step": 8220
    },
    {
      "epoch": 9.01,
      "learning_rate": 0.0035399999999999997,
      "loss": 0.1881,
      "step": 8230
    },
    {
      "epoch": 9.02,
      "learning_rate": 0.0035199999999999997,
      "loss": 0.143,
      "step": 8240
    },
    {
      "epoch": 9.03,
      "learning_rate": 0.0034999999999999996,
      "loss": 0.1667,
      "step": 8250
    },
    {
      "epoch": 9.04,
      "learning_rate": 0.00348,
      "loss": 0.1541,
      "step": 8260
    },
    {
      "epoch": 9.05,
      "learning_rate": 0.00346,
      "loss": 0.1772,
      "step": 8270
    },
    {
      "epoch": 9.06,
      "learning_rate": 0.00344,
      "loss": 0.1979,
      "step": 8280
    },
    {
      "epoch": 9.07,
      "learning_rate": 0.0034200000000000003,
      "loss": 0.1864,
      "step": 8290
    },
    {
      "epoch": 9.09,
      "learning_rate": 0.0034000000000000002,
      "loss": 0.1793,
      "step": 8300
    },
    {
      "epoch": 9.1,
      "learning_rate": 0.00338,
      "loss": 0.1923,
      "step": 8310
    },
    {
      "epoch": 9.11,
      "learning_rate": 0.00336,
      "loss": 0.2274,
      "step": 8320
    },
    {
      "epoch": 9.12,
      "learning_rate": 0.00334,
      "loss": 0.1946,
      "step": 8330
    },
    {
      "epoch": 9.13,
      "learning_rate": 0.00332,
      "loss": 0.2074,
      "step": 8340
    },
    {
      "epoch": 9.14,
      "learning_rate": 0.0033000000000000004,
      "loss": 0.2104,
      "step": 8350
    },
    {
      "epoch": 9.15,
      "learning_rate": 0.0032800000000000004,
      "loss": 0.1549,
      "step": 8360
    },
    {
      "epoch": 9.16,
      "learning_rate": 0.0032600000000000003,
      "loss": 0.1732,
      "step": 8370
    },
    {
      "epoch": 9.17,
      "learning_rate": 0.0032400000000000003,
      "loss": 0.1941,
      "step": 8380
    },
    {
      "epoch": 9.18,
      "learning_rate": 0.00322,
      "loss": 0.1568,
      "step": 8390
    },
    {
      "epoch": 9.2,
      "learning_rate": 0.0032,
      "loss": 0.1799,
      "step": 8400
    },
    {
      "epoch": 9.21,
      "learning_rate": 0.00318,
      "loss": 0.1926,
      "step": 8410
    },
    {
      "epoch": 9.22,
      "learning_rate": 0.00316,
      "loss": 0.182,
      "step": 8420
    },
    {
      "epoch": 9.23,
      "learning_rate": 0.00314,
      "loss": 0.1769,
      "step": 8430
    },
    {
      "epoch": 9.24,
      "learning_rate": 0.00312,
      "loss": 0.1581,
      "step": 8440
    },
    {
      "epoch": 9.25,
      "learning_rate": 0.0031,
      "loss": 0.1652,
      "step": 8450
    },
    {
      "epoch": 9.26,
      "learning_rate": 0.00308,
      "loss": 0.1868,
      "step": 8460
    },
    {
      "epoch": 9.27,
      "learning_rate": 0.0030600000000000002,
      "loss": 0.1788,
      "step": 8470
    },
    {
      "epoch": 9.28,
      "learning_rate": 0.00304,
      "loss": 0.1648,
      "step": 8480
    },
    {
      "epoch": 9.29,
      "learning_rate": 0.00302,
      "loss": 0.1446,
      "step": 8490
    },
    {
      "epoch": 9.3,
      "learning_rate": 0.003,
      "loss": 0.1756,
      "step": 8500
    },
    {
      "epoch": 9.32,
      "learning_rate": 0.00298,
      "loss": 0.1787,
      "step": 8510
    },
    {
      "epoch": 9.33,
      "learning_rate": 0.00296,
      "loss": 0.1869,
      "step": 8520
    },
    {
      "epoch": 9.34,
      "learning_rate": 0.00294,
      "loss": 0.1749,
      "step": 8530
    },
    {
      "epoch": 9.35,
      "learning_rate": 0.00292,
      "loss": 0.149,
      "step": 8540
    },
    {
      "epoch": 9.36,
      "learning_rate": 0.0029,
      "loss": 0.1611,
      "step": 8550
    },
    {
      "epoch": 9.37,
      "learning_rate": 0.0028799999999999997,
      "loss": 0.1762,
      "step": 8560
    },
    {
      "epoch": 9.38,
      "learning_rate": 0.0028599999999999997,
      "loss": 0.2031,
      "step": 8570
    },
    {
      "epoch": 9.39,
      "learning_rate": 0.0028399999999999996,
      "loss": 0.1708,
      "step": 8580
    },
    {
      "epoch": 9.4,
      "learning_rate": 0.0028199999999999996,
      "loss": 0.1671,
      "step": 8590
    },
    {
      "epoch": 9.41,
      "learning_rate": 0.0028000000000000004,
      "loss": 0.19,
      "step": 8600
    },
    {
      "epoch": 9.43,
      "learning_rate": 0.0027800000000000004,
      "loss": 0.1835,
      "step": 8610
    },
    {
      "epoch": 9.44,
      "learning_rate": 0.0027600000000000003,
      "loss": 0.1751,
      "step": 8620
    },
    {
      "epoch": 9.45,
      "learning_rate": 0.0027400000000000002,
      "loss": 0.1927,
      "step": 8630
    },
    {
      "epoch": 9.46,
      "learning_rate": 0.00272,
      "loss": 0.1759,
      "step": 8640
    },
    {
      "epoch": 9.47,
      "learning_rate": 0.0027,
      "loss": 0.1574,
      "step": 8650
    },
    {
      "epoch": 9.48,
      "learning_rate": 0.00268,
      "loss": 0.1424,
      "step": 8660
    },
    {
      "epoch": 9.49,
      "learning_rate": 0.00266,
      "loss": 0.1557,
      "step": 8670
    },
    {
      "epoch": 9.5,
      "learning_rate": 0.00264,
      "loss": 0.2122,
      "step": 8680
    },
    {
      "epoch": 9.51,
      "learning_rate": 0.0026200000000000004,
      "loss": 0.1733,
      "step": 8690
    },
    {
      "epoch": 9.52,
      "learning_rate": 0.0026000000000000003,
      "loss": 0.1835,
      "step": 8700
    },
    {
      "epoch": 9.53,
      "learning_rate": 0.0025800000000000003,
      "loss": 0.1973,
      "step": 8710
    },
    {
      "epoch": 9.55,
      "learning_rate": 0.00256,
      "loss": 0.1391,
      "step": 8720
    },
    {
      "epoch": 9.56,
      "learning_rate": 0.00254,
      "loss": 0.1666,
      "step": 8730
    },
    {
      "epoch": 9.57,
      "learning_rate": 0.00252,
      "loss": 0.1569,
      "step": 8740
    },
    {
      "epoch": 9.58,
      "learning_rate": 0.0025,
      "loss": 0.1943,
      "step": 8750
    },
    {
      "epoch": 9.59,
      "learning_rate": 0.00248,
      "loss": 0.2303,
      "step": 8760
    },
    {
      "epoch": 9.6,
      "learning_rate": 0.00246,
      "loss": 0.1924,
      "step": 8770
    },
    {
      "epoch": 9.61,
      "learning_rate": 0.00244,
      "loss": 0.1733,
      "step": 8780
    },
    {
      "epoch": 9.62,
      "learning_rate": 0.00242,
      "loss": 0.1969,
      "step": 8790
    },
    {
      "epoch": 9.63,
      "learning_rate": 0.0024,
      "loss": 0.165,
      "step": 8800
    },
    {
      "epoch": 9.64,
      "learning_rate": 0.0023799999999999997,
      "loss": 0.1919,
      "step": 8810
    },
    {
      "epoch": 9.66,
      "learning_rate": 0.00236,
      "loss": 0.1896,
      "step": 8820
    },
    {
      "epoch": 9.67,
      "learning_rate": 0.00234,
      "loss": 0.141,
      "step": 8830
    },
    {
      "epoch": 9.68,
      "learning_rate": 0.00232,
      "loss": 0.1638,
      "step": 8840
    },
    {
      "epoch": 9.69,
      "learning_rate": 0.0023,
      "loss": 0.1782,
      "step": 8850
    },
    {
      "epoch": 9.7,
      "learning_rate": 0.0022800000000000003,
      "loss": 0.1652,
      "step": 8860
    },
    {
      "epoch": 9.71,
      "learning_rate": 0.0022600000000000003,
      "loss": 0.1655,
      "step": 8870
    },
    {
      "epoch": 9.72,
      "learning_rate": 0.0022400000000000002,
      "loss": 0.1845,
      "step": 8880
    },
    {
      "epoch": 9.73,
      "learning_rate": 0.00222,
      "loss": 0.1887,
      "step": 8890
    },
    {
      "epoch": 9.74,
      "learning_rate": 0.0022,
      "loss": 0.1677,
      "step": 8900
    },
    {
      "epoch": 9.75,
      "learning_rate": 0.00218,
      "loss": 0.1647,
      "step": 8910
    },
    {
      "epoch": 9.76,
      "learning_rate": 0.00216,
      "loss": 0.194,
      "step": 8920
    },
    {
      "epoch": 9.78,
      "learning_rate": 0.00214,
      "loss": 0.1951,
      "step": 8930
    },
    {
      "epoch": 9.79,
      "learning_rate": 0.00212,
      "loss": 0.1966,
      "step": 8940
    },
    {
      "epoch": 9.8,
      "learning_rate": 0.0021,
      "loss": 0.1996,
      "step": 8950
    },
    {
      "epoch": 9.81,
      "learning_rate": 0.00208,
      "loss": 0.1998,
      "step": 8960
    },
    {
      "epoch": 9.82,
      "learning_rate": 0.0020599999999999998,
      "loss": 0.2101,
      "step": 8970
    },
    {
      "epoch": 9.83,
      "learning_rate": 0.0020399999999999997,
      "loss": 0.1658,
      "step": 8980
    },
    {
      "epoch": 9.84,
      "learning_rate": 0.00202,
      "loss": 0.156,
      "step": 8990
    },
    {
      "epoch": 9.85,
      "learning_rate": 0.002,
      "loss": 0.1853,
      "step": 9000
    },
    {
      "epoch": 9.86,
      "learning_rate": 0.00198,
      "loss": 0.1776,
      "step": 9010
    },
    {
      "epoch": 9.87,
      "learning_rate": 0.00196,
      "loss": 0.1868,
      "step": 9020
    },
    {
      "epoch": 9.89,
      "learning_rate": 0.00194,
      "loss": 0.1621,
      "step": 9030
    },
    {
      "epoch": 9.9,
      "learning_rate": 0.00192,
      "loss": 0.1641,
      "step": 9040
    },
    {
      "epoch": 9.91,
      "learning_rate": 0.0019,
      "loss": 0.2017,
      "step": 9050
    },
    {
      "epoch": 9.92,
      "learning_rate": 0.00188,
      "loss": 0.1725,
      "step": 9060
    },
    {
      "epoch": 9.93,
      "learning_rate": 0.00186,
      "loss": 0.175,
      "step": 9070
    },
    {
      "epoch": 9.94,
      "learning_rate": 0.00184,
      "loss": 0.1957,
      "step": 9080
    },
    {
      "epoch": 9.95,
      "learning_rate": 0.00182,
      "loss": 0.1692,
      "step": 9090
    },
    {
      "epoch": 9.96,
      "learning_rate": 0.0018,
      "loss": 0.1771,
      "step": 9100
    },
    {
      "epoch": 9.97,
      "learning_rate": 0.00178,
      "loss": 0.1913,
      "step": 9110
    },
    {
      "epoch": 9.98,
      "learning_rate": 0.0017599999999999998,
      "loss": 0.1797,
      "step": 9120
    },
    {
      "epoch": 9.99,
      "learning_rate": 0.00174,
      "loss": 0.1817,
      "step": 9130
    },
    {
      "epoch": 10.01,
      "learning_rate": 0.00172,
      "loss": 0.16,
      "step": 9140
    },
    {
      "epoch": 10.02,
      "learning_rate": 0.0017000000000000001,
      "loss": 0.1348,
      "step": 9150
    },
    {
      "epoch": 10.03,
      "learning_rate": 0.00168,
      "loss": 0.1521,
      "step": 9160
    },
    {
      "epoch": 10.04,
      "learning_rate": 0.00166,
      "loss": 0.1708,
      "step": 9170
    },
    {
      "epoch": 10.05,
      "learning_rate": 0.0016400000000000002,
      "loss": 0.1509,
      "step": 9180
    },
    {
      "epoch": 10.06,
      "learning_rate": 0.0016200000000000001,
      "loss": 0.1559,
      "step": 9190
    },
    {
      "epoch": 10.07,
      "learning_rate": 0.0016,
      "loss": 0.1591,
      "step": 9200
    },
    {
      "epoch": 10.08,
      "learning_rate": 0.00158,
      "loss": 0.1199,
      "step": 9210
    },
    {
      "epoch": 10.09,
      "learning_rate": 0.00156,
      "loss": 0.1448,
      "step": 9220
    },
    {
      "epoch": 10.1,
      "learning_rate": 0.00154,
      "loss": 0.1504,
      "step": 9230
    },
    {
      "epoch": 10.11,
      "learning_rate": 0.00152,
      "loss": 0.1544,
      "step": 9240
    },
    {
      "epoch": 10.13,
      "learning_rate": 0.0015,
      "loss": 0.1492,
      "step": 9250
    },
    {
      "epoch": 10.14,
      "learning_rate": 0.00148,
      "loss": 0.1481,
      "step": 9260
    },
    {
      "epoch": 10.15,
      "learning_rate": 0.00146,
      "loss": 0.1378,
      "step": 9270
    },
    {
      "epoch": 10.16,
      "learning_rate": 0.0014399999999999999,
      "loss": 0.1165,
      "step": 9280
    },
    {
      "epoch": 10.17,
      "learning_rate": 0.0014199999999999998,
      "loss": 0.1381,
      "step": 9290
    },
    {
      "epoch": 10.18,
      "learning_rate": 0.0014000000000000002,
      "loss": 0.1443,
      "step": 9300
    },
    {
      "epoch": 10.19,
      "learning_rate": 0.0013800000000000002,
      "loss": 0.1679,
      "step": 9310
    },
    {
      "epoch": 10.2,
      "learning_rate": 0.00136,
      "loss": 0.1328,
      "step": 9320
    },
    {
      "epoch": 10.21,
      "learning_rate": 0.00134,
      "loss": 0.1487,
      "step": 9330
    },
    {
      "epoch": 10.22,
      "learning_rate": 0.00132,
      "loss": 0.1501,
      "step": 9340
    },
    {
      "epoch": 10.24,
      "learning_rate": 0.0013000000000000002,
      "loss": 0.1532,
      "step": 9350
    },
    {
      "epoch": 10.25,
      "learning_rate": 0.00128,
      "loss": 0.1382,
      "step": 9360
    },
    {
      "epoch": 10.26,
      "learning_rate": 0.00126,
      "loss": 0.1584,
      "step": 9370
    },
    {
      "epoch": 10.27,
      "learning_rate": 0.00124,
      "loss": 0.1348,
      "step": 9380
    },
    {
      "epoch": 10.28,
      "learning_rate": 0.00122,
      "loss": 0.1329,
      "step": 9390
    },
    {
      "epoch": 10.29,
      "learning_rate": 0.0012,
      "loss": 0.1491,
      "step": 9400
    },
    {
      "epoch": 10.3,
      "learning_rate": 0.00118,
      "loss": 0.1686,
      "step": 9410
    },
    {
      "epoch": 10.31,
      "learning_rate": 0.00116,
      "loss": 0.1576,
      "step": 9420
    },
    {
      "epoch": 10.32,
      "learning_rate": 0.0011400000000000002,
      "loss": 0.169,
      "step": 9430
    },
    {
      "epoch": 10.33,
      "learning_rate": 0.0011200000000000001,
      "loss": 0.1516,
      "step": 9440
    },
    {
      "epoch": 10.34,
      "learning_rate": 0.0011,
      "loss": 0.1234,
      "step": 9450
    },
    {
      "epoch": 10.36,
      "learning_rate": 0.00108,
      "loss": 0.1329,
      "step": 9460
    },
    {
      "epoch": 10.37,
      "learning_rate": 0.00106,
      "loss": 0.13,
      "step": 9470
    },
    {
      "epoch": 10.38,
      "learning_rate": 0.00104,
      "loss": 0.1554,
      "step": 9480
    },
    {
      "epoch": 10.39,
      "learning_rate": 0.0010199999999999999,
      "loss": 0.1827,
      "step": 9490
    },
    {
      "epoch": 10.4,
      "learning_rate": 0.001,
      "loss": 0.1371,
      "step": 9500
    },
    {
      "epoch": 10.41,
      "learning_rate": 0.00098,
      "loss": 0.1619,
      "step": 9510
    },
    {
      "epoch": 10.42,
      "learning_rate": 0.00096,
      "loss": 0.1726,
      "step": 9520
    },
    {
      "epoch": 10.43,
      "learning_rate": 0.00094,
      "loss": 0.1941,
      "step": 9530
    },
    {
      "epoch": 10.44,
      "learning_rate": 0.00092,
      "loss": 0.1513,
      "step": 9540
    },
    {
      "epoch": 10.45,
      "learning_rate": 0.0009,
      "loss": 0.1577,
      "step": 9550
    },
    {
      "epoch": 10.47,
      "learning_rate": 0.0008799999999999999,
      "loss": 0.125,
      "step": 9560
    },
    {
      "epoch": 10.48,
      "learning_rate": 0.00086,
      "loss": 0.1591,
      "step": 9570
    },
    {
      "epoch": 10.49,
      "learning_rate": 0.00084,
      "loss": 0.143,
      "step": 9580
    },
    {
      "epoch": 10.5,
      "learning_rate": 0.0008200000000000001,
      "loss": 0.1533,
      "step": 9590
    },
    {
      "epoch": 10.51,
      "learning_rate": 0.0008,
      "loss": 0.1471,
      "step": 9600
    },
    {
      "epoch": 10.52,
      "learning_rate": 0.00078,
      "loss": 0.1286,
      "step": 9610
    },
    {
      "epoch": 10.53,
      "learning_rate": 0.00076,
      "loss": 0.1466,
      "step": 9620
    },
    {
      "epoch": 10.54,
      "learning_rate": 0.00074,
      "loss": 0.1424,
      "step": 9630
    },
    {
      "epoch": 10.55,
      "learning_rate": 0.0007199999999999999,
      "loss": 0.1715,
      "step": 9640
    },
    {
      "epoch": 10.56,
      "learning_rate": 0.0007000000000000001,
      "loss": 0.1509,
      "step": 9650
    },
    {
      "epoch": 10.57,
      "learning_rate": 0.00068,
      "loss": 0.1306,
      "step": 9660
    },
    {
      "epoch": 10.59,
      "learning_rate": 0.00066,
      "loss": 0.1631,
      "step": 9670
    },
    {
      "epoch": 10.6,
      "learning_rate": 0.00064,
      "loss": 0.1496,
      "step": 9680
    },
    {
      "epoch": 10.61,
      "learning_rate": 0.00062,
      "loss": 0.1462,
      "step": 9690
    },
    {
      "epoch": 10.62,
      "learning_rate": 0.0006,
      "loss": 0.1394,
      "step": 9700
    },
    {
      "epoch": 10.63,
      "learning_rate": 0.00058,
      "loss": 0.1451,
      "step": 9710
    },
    {
      "epoch": 10.64,
      "learning_rate": 0.0005600000000000001,
      "loss": 0.1429,
      "step": 9720
    },
    {
      "epoch": 10.65,
      "learning_rate": 0.00054,
      "loss": 0.1605,
      "step": 9730
    },
    {
      "epoch": 10.66,
      "learning_rate": 0.00052,
      "loss": 0.1448,
      "step": 9740
    },
    {
      "epoch": 10.67,
      "learning_rate": 0.0005,
      "loss": 0.136,
      "step": 9750
    },
    {
      "epoch": 10.68,
      "learning_rate": 0.00048,
      "loss": 0.1571,
      "step": 9760
    },
    {
      "epoch": 10.7,
      "learning_rate": 0.00046,
      "loss": 0.151,
      "step": 9770
    },
    {
      "epoch": 10.71,
      "learning_rate": 0.00043999999999999996,
      "loss": 0.1359,
      "step": 9780
    },
    {
      "epoch": 10.72,
      "learning_rate": 0.00042,
      "loss": 0.1449,
      "step": 9790
    },
    {
      "epoch": 10.73,
      "learning_rate": 0.0004,
      "loss": 0.1531,
      "step": 9800
    },
    {
      "epoch": 10.74,
      "learning_rate": 0.00038,
      "loss": 0.1559,
      "step": 9810
    },
    {
      "epoch": 10.75,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.1211,
      "step": 9820
    },
    {
      "epoch": 10.76,
      "learning_rate": 0.00034,
      "loss": 0.1441,
      "step": 9830
    },
    {
      "epoch": 10.77,
      "learning_rate": 0.00032,
      "loss": 0.164,
      "step": 9840
    },
    {
      "epoch": 10.78,
      "learning_rate": 0.0003,
      "loss": 0.1295,
      "step": 9850
    },
    {
      "epoch": 10.79,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.1697,
      "step": 9860
    },
    {
      "epoch": 10.8,
      "learning_rate": 0.00026,
      "loss": 0.1654,
      "step": 9870
    },
    {
      "epoch": 10.82,
      "learning_rate": 0.00024,
      "loss": 0.1397,
      "step": 9880
    },
    {
      "epoch": 10.83,
      "learning_rate": 0.00021999999999999998,
      "loss": 0.1528,
      "step": 9890
    },
    {
      "epoch": 10.84,
      "learning_rate": 0.0002,
      "loss": 0.1501,
      "step": 9900
    },
    {
      "epoch": 10.85,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.1478,
      "step": 9910
    },
    {
      "epoch": 10.86,
      "learning_rate": 0.00016,
      "loss": 0.1518,
      "step": 9920
    },
    {
      "epoch": 10.87,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.1631,
      "step": 9930
    },
    {
      "epoch": 10.88,
      "learning_rate": 0.00012,
      "loss": 0.1386,
      "step": 9940
    },
    {
      "epoch": 10.89,
      "learning_rate": 0.0001,
      "loss": 0.1449,
      "step": 9950
    },
    {
      "epoch": 10.9,
      "learning_rate": 8e-05,
      "loss": 0.1713,
      "step": 9960
    },
    {
      "epoch": 10.91,
      "learning_rate": 6e-05,
      "loss": 0.1352,
      "step": 9970
    },
    {
      "epoch": 10.93,
      "learning_rate": 4e-05,
      "loss": 0.1338,
      "step": 9980
    },
    {
      "epoch": 10.94,
      "learning_rate": 2e-05,
      "loss": 0.134,
      "step": 9990
    },
    {
      "epoch": 10.95,
      "learning_rate": 0.0,
      "loss": 0.1643,
      "step": 10000
    },
    {
      "epoch": 10.95,
      "step": 10000,
      "total_flos": 3.4650554980368384e+17,
      "train_loss": 0.6779042373657227,
      "train_runtime": 21490.938,
      "train_samples_per_second": 7.445,
      "train_steps_per_second": 0.465
    }
  ],
  "max_steps": 10000,
  "num_train_epochs": 11,
  "total_flos": 3.4650554980368384e+17,
  "trial_name": null,
  "trial_params": null
}
